{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Immigration Database & pipelines creation for Machine Learning studies\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This project undertakes the creation of a series of ETL transformations whose ultimate goal is the creation of a database that allows the run of Machine Learning algorithms that can unveil hidden patterns in immigration data.\n",
    "\n",
    "Indeed, these studies want to analyze the impact of several ambiental and socioeconomic factors in the US immigrant population in relation to their incoming and distribution within the US.\n",
    "\n",
    "We will start small, by gathering and cleaning the data, but only joining some econonmic data to the immigration tables, leaving the rest of the tables readily available at a one-join-statement distance, when the need of more columns presents.\n",
    "\n",
    "At end, we will store the heavily modified Immigration table in a parquet file, so as it is possible to load it and use it without the need of running all these steps from scratch.\n",
    "\n",
    "The project follows the follow steps:\n",
    "\n",
    "* Step 1: Scope the Project and gather and present the Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime as dt\n",
    "from pyspark.sql import SparkSession\n",
    "from  pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "\n",
    "As we said, the ultimate goal is to run Machine Learning models to determine whether some hidden relationships might exist between conditions of immigrants's home countries and their arrival and distribution within the US.\n",
    "\n",
    "We will start small, so for a first iteration, we will try to determine whether a relationship between our resident's city or choice and their homeplace's mean temperatures hold any relationship.\n",
    "\n",
    "#### Data\n",
    "\n",
    "For this purpose will use only a big dataset from the US National Tourism and Trade Office, another one from Opensoft relating the demographics of cities along the US, a dataset of airport codes that might help us in locating our resident's countries of birth, a big dataset of temperatures by city and a dataset of countries by GDP per capita.\n",
    "\n",
    "- I94 Immigration Data\n",
    "- World Temperature Data\n",
    "- U.S. City Demographic Data\n",
    "- Airport Code Table\n",
    "- Countries GDP per capita\n",
    "\n",
    "We will import and describe now these 5 datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I94 Immigration Data:**\n",
    "\n",
    "This data comes from the US National Tourism and Trade Office. A data dictionary is also included in the workspace. \n",
    "\n",
    "The data comes from: https://travel.trade.gov/research/reports/i94/historical/2016.html.\n",
    "\n",
    "We have also a sample file we will use to take a look at the data in csv format before reading it all in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto  gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016       F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016       M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016       M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016       M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016       F   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658267e+10  00782        WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_path = 'immigration_data_sample.csv'\n",
    "df_immigration = pd.read_csv(immigration_path)\n",
    "df_immigration.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data we have a data dictionary, the we proceed to read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"libname library 'Your file location' ;\\n\",\n",
       " 'proc format library=library ;\\n',\n",
       " '\\n',\n",
       " '/* I94YR - 4 digit year */\\n',\n",
       " '\\n',\n",
       " '/* I94MON - Numeric month */\\n',\n",
       " '\\n',\n",
       " '/* I94CIT & I94RES - This format shows all the valid and invalid codes for processing */\\n',\n",
       " '  value i94cntyl\\n',\n",
       " \"   582 =  'MEXICO Air Sea, and Not Reported (I-94, no land arrivals)'\\n\",\n",
       " \"   236 =  'AFGHANISTAN'\\n\",\n",
       " \"   101 =  'ALBANIA'\\n\",\n",
       " \"   316 =  'ALGERIA'\\n\",\n",
       " \"   102 =  'ANDORRA'\\n\",\n",
       " \"   324 =  'ANGOLA'\\n\",\n",
       " \"   529 =  'ANGUILLA'\\n\",\n",
       " \"   518 =  'ANTIGUA-BARBUDA'\\n\",\n",
       " \"   687 =  'ARGENTINA '\\n\",\n",
       " \"   151 =  'ARMENIA'\\n\",\n",
       " \"   532 =  'ARUBA'\\n\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAS_label_descriptions = \"./Auxiliary/I94_SAS_Labels_Descriptions.SAS\"\n",
    "label_descriptions = open(SAS_label_descriptions)\n",
    "label_descriptions.readlines()[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning with Regex, we extract the information on what are our columns and the information they contain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/* I94YR - 4 digit year */',\n",
       " '/* I94MON - Numeric month */',\n",
       " '/* I94CIT & I94RES - This format shows all the valid and invalid codes for processing */',\n",
       " '/* I94PORT - This format shows all the valid and invalid codes for processing */',\n",
       " '/* ARRDATE is the Arrival Date in the USA. It is a SAS date numeric field that a ',\n",
       " '/* I94MODE - There are missing values as well as not reported (9) */',\n",
       " '/* I94ADDR - There is lots of invalid codes in this variable and the list below ',\n",
       " '/* DEPDATE is the Departure Date from the USA. It is a SAS date numeric field that ',\n",
       " '/* I94BIR - Age of Respondent in Years */',\n",
       " '/* I94VISA - Visa codes collapsed into three categories:',\n",
       " '/* COUNT - Used for summary statistics */',\n",
       " '/* DTADFILE - Character Date Field - Date added to I-94 Files - CIC does not use */',\n",
       " '/* VISAPOST - Department of State where where Visa was issued - CIC does not use */',\n",
       " '/* OCCUP - Occupation that will be performed in U.S. - CIC does not use */',\n",
       " '/* ENTDEPA - Arrival Flag - admitted or paroled into the U.S. - CIC does not use */',\n",
       " '/* ENTDEPD - Departure Flag - Departed, lost I-94 or is deceased - CIC does not use */',\n",
       " '/* ENTDEPU - Update Flag - Either apprehended, overstayed, adjusted to perm residence - CIC does not use */',\n",
       " '/* MATFLAG - Match flag - Match of arrival and departure records */',\n",
       " '/* BIRYEAR - 4 digit year of birth */',\n",
       " '/* DTADDTO - Character Date Field - Date to which admitted to U.S. (allowed to stay until) - CIC does not use */',\n",
       " '/* GENDER - Non-immigrant sex */',\n",
       " '/* INSNUM - INS number */',\n",
       " '/* AIRLINE - Airline used to arrive in U.S. */',\n",
       " '/* ADMNUM - Admission Number */',\n",
       " '/* FLTNO - Flight number of Airline used to arrive in U.S. */',\n",
       " '/* VISATYPE - Class of admission legally admitting the non-immigrant to temporarily stay in U.S. */']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_obj = re.compile(r'\\/\\*(.*)')\n",
    "I94_data_columns_expl = list()\n",
    "\n",
    "label_descriptions = open(SAS_label_descriptions)\n",
    "for data in label_descriptions:\n",
    "    match = re_obj.search(data)\n",
    "    if match != None:\n",
    "         I94_data_columns_expl.append(match[0])\n",
    "    \n",
    "I94_data_columns_expl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now proceed to import to a dataframe one of the original SAS files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAS_immigration = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df_immigration_trial = pd.read_sas(SAS_immigration, format='sas7bdat', encoding=\"ISO-8859-1\")\n",
    "# format=None, index=None, encoding=None, chunksize=None, iterator=False)                                 \n",
    "# format='sas7bdat', encoding=\"ISO-8859-1\")\n",
    "                                   \n",
    "df_immigration_trial.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Airport Code Table:** \n",
    "\n",
    "This is a simple table of airport codes and corresponding cities. \n",
    "\n",
    "It comes from:\n",
    "https://datahub.io/core/airport-codes#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports_path = 'airport-codes_csv.csv'\n",
    "df_airports = pd.read_csv(airports_path, encoding=\"ISO-8859-1\")\n",
    "df_airports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22500</th>\n",
       "      <td>GCLA</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>La Palma Airport</td>\n",
       "      <td>107.0</td>\n",
       "      <td>EU</td>\n",
       "      <td>ES</td>\n",
       "      <td>ES-CN</td>\n",
       "      <td>Sta Cruz de la Palma, La Palma Island</td>\n",
       "      <td>GCLA</td>\n",
       "      <td>SPC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.7556, 28.626499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22502</th>\n",
       "      <td>GCLP</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Gran Canaria Airport</td>\n",
       "      <td>78.0</td>\n",
       "      <td>EU</td>\n",
       "      <td>ES</td>\n",
       "      <td>ES-CN</td>\n",
       "      <td>Gran Canaria Island</td>\n",
       "      <td>GCLP</td>\n",
       "      <td>LPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15.38659954071045, 27.931900024414062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22504</th>\n",
       "      <td>GCTS</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Tenerife South Airport</td>\n",
       "      <td>209.0</td>\n",
       "      <td>EU</td>\n",
       "      <td>ES</td>\n",
       "      <td>ES-CN</td>\n",
       "      <td>Tenerife Island</td>\n",
       "      <td>GCTS</td>\n",
       "      <td>TFS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.5725002289, 28.044500351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22506</th>\n",
       "      <td>GCXO</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Tenerife Norte Airport</td>\n",
       "      <td>2076.0</td>\n",
       "      <td>EU</td>\n",
       "      <td>ES</td>\n",
       "      <td>ES-CN</td>\n",
       "      <td>Tenerife Island</td>\n",
       "      <td>GCXO</td>\n",
       "      <td>TFN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.3414993286, 28.4827003479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30787</th>\n",
       "      <td>LEAL</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Alicante International Airport</td>\n",
       "      <td>142.0</td>\n",
       "      <td>EU</td>\n",
       "      <td>ES</td>\n",
       "      <td>ES-V</td>\n",
       "      <td>Alicante</td>\n",
       "      <td>LEAL</td>\n",
       "      <td>ALC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.5581560134887695, 38.28219985961914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30799</th>\n",
       "      <td>LEBL</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Barcelona International Airport</td>\n",
       "      <td>12.0</td>\n",
       "      <td>EU</td>\n",
       "      <td>ES</td>\n",
       "      <td>ES-CT</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>LEBL</td>\n",
       "      <td>BCN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.07846, 41.2971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30863</th>\n",
       "      <td>LEMD</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Adolfo SuÃƒÂƒÃ‚Â¡rez MadridÃƒÂ¢Ã‚Â€Ã‚Â“Barajas Airport</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>EU</td>\n",
       "      <td>ES</td>\n",
       "      <td>ES-M</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>LEMD</td>\n",
       "      <td>MAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.56264, 40.471926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30865</th>\n",
       "      <td>LEMG</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>MÃƒÂƒÃ‚Â¡laga Airport</td>\n",
       "      <td>53.0</td>\n",
       "      <td>EU</td>\n",
       "      <td>ES</td>\n",
       "      <td>ES-AN</td>\n",
       "      <td>MÃƒÂƒÃ‚Â¡laga</td>\n",
       "      <td>LEMG</td>\n",
       "      <td>AGP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.499110221862793, 36.67490005493164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30884</th>\n",
       "      <td>LEPA</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Palma De Mallorca Airport</td>\n",
       "      <td>27.0</td>\n",
       "      <td>EU</td>\n",
       "      <td>ES</td>\n",
       "      <td>ES-PM</td>\n",
       "      <td>Palma De Mallorca</td>\n",
       "      <td>LEPA</td>\n",
       "      <td>PMI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.73881006241, 39.551700592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>LEST</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Santiago de Compostela Airport</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>EU</td>\n",
       "      <td>ES</td>\n",
       "      <td>ES-GA</td>\n",
       "      <td>Santiago de Compostela</td>\n",
       "      <td>LEST</td>\n",
       "      <td>SCQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.415140151977539, 42.89630126953125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ident           type                                          name  \\\n",
       "22500  GCLA  large_airport                              La Palma Airport   \n",
       "22502  GCLP  large_airport                          Gran Canaria Airport   \n",
       "22504  GCTS  large_airport                        Tenerife South Airport   \n",
       "22506  GCXO  large_airport                        Tenerife Norte Airport   \n",
       "30787  LEAL  large_airport                Alicante International Airport   \n",
       "30799  LEBL  large_airport               Barcelona International Airport   \n",
       "30863  LEMD  large_airport  Adolfo SuÃƒÂƒÃ‚Â¡rez MadridÃƒÂ¢Ã‚Â€Ã‚Â“Barajas Airport   \n",
       "30865  LEMG  large_airport                             MÃƒÂƒÃ‚Â¡laga Airport   \n",
       "30884  LEPA  large_airport                     Palma De Mallorca Airport   \n",
       "30911  LEST  large_airport                Santiago de Compostela Airport   \n",
       "\n",
       "       elevation_ft continent iso_country iso_region  \\\n",
       "22500         107.0        EU          ES      ES-CN   \n",
       "22502          78.0        EU          ES      ES-CN   \n",
       "22504         209.0        EU          ES      ES-CN   \n",
       "22506        2076.0        EU          ES      ES-CN   \n",
       "30787         142.0        EU          ES       ES-V   \n",
       "30799          12.0        EU          ES      ES-CT   \n",
       "30863        1998.0        EU          ES       ES-M   \n",
       "30865          53.0        EU          ES      ES-AN   \n",
       "30884          27.0        EU          ES      ES-PM   \n",
       "30911        1213.0        EU          ES      ES-GA   \n",
       "\n",
       "                                municipality gps_code iata_code local_code  \\\n",
       "22500  Sta Cruz de la Palma, La Palma Island     GCLA       SPC        NaN   \n",
       "22502                    Gran Canaria Island     GCLP       LPA        NaN   \n",
       "22504                        Tenerife Island     GCTS       TFS        NaN   \n",
       "22506                        Tenerife Island     GCXO       TFN        NaN   \n",
       "30787                               Alicante     LEAL       ALC        NaN   \n",
       "30799                              Barcelona     LEBL       BCN        NaN   \n",
       "30863                                 Madrid     LEMD       MAD        NaN   \n",
       "30865                              MÃƒÂƒÃ‚Â¡laga     LEMG       AGP        NaN   \n",
       "30884                      Palma De Mallorca     LEPA       PMI        NaN   \n",
       "30911                 Santiago de Compostela     LEST       SCQ        NaN   \n",
       "\n",
       "                                  coordinates  \n",
       "22500                     -17.7556, 28.626499  \n",
       "22502  -15.38659954071045, 27.931900024414062  \n",
       "22504            -16.5725002289, 28.044500351  \n",
       "22506           -16.3414993286, 28.4827003479  \n",
       "30787  -0.5581560134887695, 38.28219985961914  \n",
       "30799                        2.07846, 41.2971  \n",
       "30863                     -3.56264, 40.471926  \n",
       "30865   -4.499110221862793, 36.67490005493164  \n",
       "30884             2.73881006241, 39.551700592  \n",
       "30911   -8.415140151977539, 42.89630126953125  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports[(df_airports['iso_country'] == 'ES')&(df_airports['type']=='large_airport')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**U.S. City Demographic Data:**\n",
    "    \n",
    "This data comes from OpenSoft. \n",
    "\n",
    "You can read more about it here:\n",
    "        \n",
    "https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_path = 'us-cities-demographics.csv'\n",
    "df_demographics = pd.read_csv(demographics_path, sep=\";\")\n",
    "df_demographics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**World Temperature Data:** \n",
    "\n",
    "xThis dataset came from Kaggle. You can read more about it here:\n",
    "https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Ã…rhus   \n",
       "1  1743-12-01                 NaN                            NaN  Ã…rhus   \n",
       "2  1744-01-01                 NaN                            NaN  Ã…rhus   \n",
       "3  1744-02-01                 NaN                            NaN  Ã…rhus   \n",
       "4  1744-03-01                 NaN                            NaN  Ã…rhus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperatures_path = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_temperatures = pd.read_csv(temperatures_path, nrows=100000)\n",
    "df_temperatures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Countries GDP per capita:**\n",
    "    \n",
    "Data from the Word Bank datasets:\n",
    "    \n",
    "https://data.worldbank.org/indicator/NY.GDP.PCAP.CD?view=chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Indicator Code</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>...</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>GDP per capita (current US$)</td>\n",
       "      <td>NY.GDP.PCAP.CD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>23512.602600</td>\n",
       "      <td>24985.993280</td>\n",
       "      <td>24713.698050</td>\n",
       "      <td>26189.435510</td>\n",
       "      <td>26647.938100</td>\n",
       "      <td>27980.880700</td>\n",
       "      <td>28281.350480</td>\n",
       "      <td>29007.693000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>GDP per capita (current US$)</td>\n",
       "      <td>NY.GDP.PCAP.CD</td>\n",
       "      <td>59.773194</td>\n",
       "      <td>59.860874</td>\n",
       "      <td>58.458015</td>\n",
       "      <td>78.706388</td>\n",
       "      <td>82.095231</td>\n",
       "      <td>101.108305</td>\n",
       "      <td>...</td>\n",
       "      <td>543.303042</td>\n",
       "      <td>591.162759</td>\n",
       "      <td>641.871479</td>\n",
       "      <td>637.165523</td>\n",
       "      <td>613.856689</td>\n",
       "      <td>578.466353</td>\n",
       "      <td>547.228110</td>\n",
       "      <td>556.302002</td>\n",
       "      <td>524.162881</td>\n",
       "      <td>502.115487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>GDP per capita (current US$)</td>\n",
       "      <td>NY.GDP.PCAP.CD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3587.883798</td>\n",
       "      <td>4615.468028</td>\n",
       "      <td>5100.095808</td>\n",
       "      <td>5254.882338</td>\n",
       "      <td>5408.410496</td>\n",
       "      <td>4166.979684</td>\n",
       "      <td>3506.072885</td>\n",
       "      <td>4095.812942</td>\n",
       "      <td>3289.646664</td>\n",
       "      <td>2973.591160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>GDP per capita (current US$)</td>\n",
       "      <td>NY.GDP.PCAP.CD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4094.350334</td>\n",
       "      <td>4437.142885</td>\n",
       "      <td>4247.629984</td>\n",
       "      <td>4413.060861</td>\n",
       "      <td>4578.631994</td>\n",
       "      <td>3952.801215</td>\n",
       "      <td>4124.055726</td>\n",
       "      <td>4531.020806</td>\n",
       "      <td>5284.380184</td>\n",
       "      <td>5352.857411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>AND</td>\n",
       "      <td>GDP per capita (current US$)</td>\n",
       "      <td>NY.GDP.PCAP.CD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>40852.666780</td>\n",
       "      <td>43335.328860</td>\n",
       "      <td>38686.461260</td>\n",
       "      <td>39538.766720</td>\n",
       "      <td>41303.929370</td>\n",
       "      <td>35762.523070</td>\n",
       "      <td>37474.665410</td>\n",
       "      <td>38962.880350</td>\n",
       "      <td>41793.055260</td>\n",
       "      <td>40886.391160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Name Country Code                Indicator Name  Indicator Code  \\\n",
       "0        Aruba          ABW  GDP per capita (current US$)  NY.GDP.PCAP.CD   \n",
       "1  Afghanistan          AFG  GDP per capita (current US$)  NY.GDP.PCAP.CD   \n",
       "2       Angola          AGO  GDP per capita (current US$)  NY.GDP.PCAP.CD   \n",
       "3      Albania          ALB  GDP per capita (current US$)  NY.GDP.PCAP.CD   \n",
       "4      Andorra          AND  GDP per capita (current US$)  NY.GDP.PCAP.CD   \n",
       "\n",
       "        1960       1961       1962       1963       1964        1965  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "1  59.773194  59.860874  58.458015  78.706388  82.095231  101.108305   \n",
       "2        NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "3        NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "4        NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "\n",
       "       ...               2010          2011          2012          2013  \\\n",
       "0      ...       23512.602600  24985.993280  24713.698050  26189.435510   \n",
       "1      ...         543.303042    591.162759    641.871479    637.165523   \n",
       "2      ...        3587.883798   4615.468028   5100.095808   5254.882338   \n",
       "3      ...        4094.350334   4437.142885   4247.629984   4413.060861   \n",
       "4      ...       40852.666780  43335.328860  38686.461260  39538.766720   \n",
       "\n",
       "           2014          2015          2016          2017          2018  \\\n",
       "0  26647.938100  27980.880700  28281.350480  29007.693000           NaN   \n",
       "1    613.856689    578.466353    547.228110    556.302002    524.162881   \n",
       "2   5408.410496   4166.979684   3506.072885   4095.812942   3289.646664   \n",
       "3   4578.631994   3952.801215   4124.055726   4531.020806   5284.380184   \n",
       "4  41303.929370  35762.523070  37474.665410  38962.880350  41793.055260   \n",
       "\n",
       "           2019  \n",
       "0           NaN  \n",
       "1    502.115487  \n",
       "2   2973.591160  \n",
       "3   5352.857411  \n",
       "4  40886.391160  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_path = 'Countries_GDP_per_capita.csv'\n",
    "df_countries = pd.read_csv(countries_path, sep = \";\")\n",
    "df_countries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "\n",
    "Now that we have taken a quick peak on our data, we will take a closer look to notice its format and particularities.\n",
    "\n",
    "We will focus on missing and duplicate data, appart from the column formats.\n",
    "\n",
    "With such purposes in mind, we will define a function to apply to all of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preliminary_checkings(df):\n",
    "    print(\"Total number of rows is {}\".format(df.shape[0]))\n",
    "    print(\"The number of null values is {}\".format(sum(df.isnull().values.ravel())))\n",
    "    print((\"The number of rows with some null values is {}\".format(sum([True for idx,row in df.iterrows() if any(row.isnull())]))))\n",
    "    print(\"Total number of duplicated rows is {}\\n\".format(sum(df.duplicated())))\n",
    "    print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checks:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the checkings function to our immigration sample dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows is 1000\n",
      "The number of null values is 3961\n",
      "The number of rows with some null values is 1000\n",
      "Total number of duplicated rows is 0\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 29 columns):\n",
      "Unnamed: 0    1000 non-null int64\n",
      "cicid         1000 non-null float64\n",
      "i94yr         1000 non-null float64\n",
      "i94mon        1000 non-null float64\n",
      "i94cit        1000 non-null float64\n",
      "i94res        1000 non-null float64\n",
      "i94port       1000 non-null object\n",
      "arrdate       1000 non-null float64\n",
      "i94mode       1000 non-null float64\n",
      "i94addr       941 non-null object\n",
      "depdate       951 non-null float64\n",
      "i94bir        1000 non-null float64\n",
      "i94visa       1000 non-null float64\n",
      "count         1000 non-null float64\n",
      "dtadfile      1000 non-null int64\n",
      "visapost      382 non-null object\n",
      "occup         4 non-null object\n",
      "entdepa       1000 non-null object\n",
      "entdepd       954 non-null object\n",
      "entdepu       0 non-null float64\n",
      "matflag       954 non-null object\n",
      "biryear       1000 non-null float64\n",
      "dtaddto       1000 non-null object\n",
      "gender        859 non-null object\n",
      "insnum        35 non-null float64\n",
      "airline       967 non-null object\n",
      "admnum        1000 non-null float64\n",
      "fltno         992 non-null object\n",
      "visatype      1000 non-null object\n",
      "dtypes: float64(15), int64(2), object(12)\n",
      "memory usage: 226.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "preliminary_checkings(df_immigration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that no row is free of nulls, but that most of them come from a small bunch of columns.\n",
    "\n",
    "After consulting in the data dictionary, we decide to remove four columns that will not bring much information to our desired goals, and that also hold a pretty decent ammount of null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration_columns_with_nulls = ['entdepu', 'occup', 'insnum', 'visapost']\n",
    "df_immigration.drop(df_immigration_columns_with_nulls, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the results are much better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows is 1000\n",
      "The number of null values is 382\n",
      "The number of rows with some null values is 243\n",
      "Total number of duplicated rows is 0\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 25 columns):\n",
      "Unnamed: 0    1000 non-null int64\n",
      "cicid         1000 non-null float64\n",
      "i94yr         1000 non-null float64\n",
      "i94mon        1000 non-null float64\n",
      "i94cit        1000 non-null float64\n",
      "i94res        1000 non-null float64\n",
      "i94port       1000 non-null object\n",
      "arrdate       1000 non-null float64\n",
      "i94mode       1000 non-null float64\n",
      "i94addr       941 non-null object\n",
      "depdate       951 non-null float64\n",
      "i94bir        1000 non-null float64\n",
      "i94visa       1000 non-null float64\n",
      "count         1000 non-null float64\n",
      "dtadfile      1000 non-null int64\n",
      "entdepa       1000 non-null object\n",
      "entdepd       954 non-null object\n",
      "matflag       954 non-null object\n",
      "biryear       1000 non-null float64\n",
      "dtaddto       1000 non-null object\n",
      "gender        859 non-null object\n",
      "airline       967 non-null object\n",
      "admnum        1000 non-null float64\n",
      "fltno         992 non-null object\n",
      "visatype      1000 non-null object\n",
      "dtypes: float64(13), int64(2), object(10)\n",
      "memory usage: 195.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "preliminary_checkings(df_immigration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also check the dataset to look for meaning for the mmisterious 'Unnamed: 0' column.\n",
    "\n",
    "We suspect that this column holds the visitor's id.\n",
    "\n",
    "We will see, checking for duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, cicid, i94yr, i94mon, i94cit, i94res, i94port, arrdate, i94mode, i94addr, depdate, i94bir, i94visa, count, dtadfile, entdepa, entdepd, matflag, biryear, dtaddto, gender, airline, admnum, fltno, visatype]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 25 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration[df_immigration['Unnamed: 0'].duplicated() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking it up, we see that CIC corresponds to Citizenship and Immigration Canada.\n",
    "\n",
    "We check for duplicates, and if there are not any, the 1-on-1 relationship between 'Unnamed: 0' and cicid would be granted, providing support for our theory about that first column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, cicid, i94yr, i94mon, i94cit, i94res, i94port, arrdate, i94mode, i94addr, depdate, i94bir, i94visa, count, dtadfile, entdepa, entdepd, matflag, biryear, dtaddto, gender, airline, admnum, fltno, visatype]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration[df_immigration['cicid'].duplicated() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check the airports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows is 55075\n",
      "The number of null values is 126968\n",
      "The number of rows with some null values is 54397\n",
      "Total number of duplicated rows is 0\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55075 entries, 0 to 55074\n",
      "Data columns (total 12 columns):\n",
      "ident           55075 non-null object\n",
      "type            55075 non-null object\n",
      "name            55075 non-null object\n",
      "elevation_ft    48069 non-null float64\n",
      "continent       27356 non-null object\n",
      "iso_country     54828 non-null object\n",
      "iso_region      55075 non-null object\n",
      "municipality    49399 non-null object\n",
      "gps_code        41030 non-null object\n",
      "iata_code       9189 non-null object\n",
      "local_code      28686 non-null object\n",
      "coordinates     55075 non-null object\n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 5.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "preliminary_checkings(df_airports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceeding as with the immigraiton data, we remove two columns from our dataset that bring little information for us, but that are full of null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airports_columns_with_nulls = ['continent', 'elevation_ft']\n",
    "df_airports.drop(df_airports_columns_with_nulls, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows is 55075\n",
      "The number of null values is 92243\n",
      "The number of rows with some null values is 52299\n",
      "Total number of duplicated rows is 0\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55075 entries, 0 to 55074\n",
      "Data columns (total 10 columns):\n",
      "ident           55075 non-null object\n",
      "type            55075 non-null object\n",
      "name            55075 non-null object\n",
      "iso_country     54828 non-null object\n",
      "iso_region      55075 non-null object\n",
      "municipality    49399 non-null object\n",
      "gps_code        41030 non-null object\n",
      "iata_code       9189 non-null object\n",
      "local_code      28686 non-null object\n",
      "coordinates     55075 non-null object\n",
      "dtypes: object(10)\n",
      "memory usage: 4.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "preliminary_checkings(df_airports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we check for duplicates in the 'ident' column (above we check for duplicated rows):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ident, type, name, iso_country, iso_region, municipality, gps_code, iata_code, local_code, coordinates]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports[df_airports['ident'].duplicated() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is turn for the df_demographics dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows is 2891\n",
      "The number of null values is 48\n",
      "The number of rows with some null values is 16\n",
      "Total number of duplicated rows is 0\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      "City                      2891 non-null object\n",
      "State                     2891 non-null object\n",
      "Median Age                2891 non-null float64\n",
      "Male Population           2888 non-null float64\n",
      "Female Population         2888 non-null float64\n",
      "Total Population          2891 non-null int64\n",
      "Number of Veterans        2878 non-null float64\n",
      "Foreign-born              2878 non-null float64\n",
      "Average Household Size    2875 non-null float64\n",
      "State Code                2891 non-null object\n",
      "Race                      2891 non-null object\n",
      "Count                     2891 non-null int64\n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "preliminary_checkings(df_demographics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the temperatures dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows is 100000\n",
      "The number of null values is 8548\n",
      "The number of rows with some null values is 4274\n",
      "Total number of duplicated rows is 0\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 7 columns):\n",
      "dt                               100000 non-null object\n",
      "AverageTemperature               95726 non-null float64\n",
      "AverageTemperatureUncertainty    95726 non-null float64\n",
      "City                             100000 non-null object\n",
      "Country                          100000 non-null object\n",
      "Latitude                         100000 non-null object\n",
      "Longitude                        100000 non-null object\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 5.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "preliminary_checkings(df_temperatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that those two datasets are fairly clean.\n",
    "\n",
    "Now, we go for the last dataset, the df_countries. We saw above that there were a pretty big ammount of columns. We will check on that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
       "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
       "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
       "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
       "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
       "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
       "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
       "       '2014', '2015', '2016', '2017', '2018', '2019'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_countries.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are many columns. As we are interested only in the recent data (we are checking on present day immigration) we will throw away all data from 1960 to 2009:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_columns_to_drop = [str(i) for i in range(1960,2010)]\n",
    "list_columns_to_drop.append('Indicator Name')\n",
    "list_columns_to_drop.append('Indicator Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countries.drop(list_columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this structure is also not the industry standard, so we are going to reshape or dataframe so there is a unique column holding all the values for the different years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_columns_indicators = ['Country Name', 'Country Code']\n",
    "list_columns_to_melt = [str(i) for i in range(2010,2020)]\n",
    "\n",
    "df_countries = df_countries.melt(id_vars = list_columns_indicators, var_name = 'year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we run our standard checkings procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows is 2640\n",
      "The number of null values is 169\n",
      "The number of rows with some null values is 169\n",
      "Total number of duplicated rows is 0\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2640 entries, 0 to 2639\n",
      "Data columns (total 4 columns):\n",
      "Country Name    2640 non-null object\n",
      "Country Code    2640 non-null object\n",
      "year            2640 non-null object\n",
      "value           2471 non-null float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 82.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "preliminary_checkings(df_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our preliminary analysis, seems nice.\n",
    "\n",
    "Also, it is noticeable that we have not found a single duplicated value (bearing in mind that, from the immigration and temperature data we have only taken a small sample, of course)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Cleaning Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of this section we looked at our data and only dropped some columns that held a fair share of nulls and were of no practical use.\n",
    "\n",
    "Only in the case of the df_countries dataset we did a more serious job, as there were changes it structure required before assesing its content.\n",
    "\n",
    "Now, in this second part we will clean our data, adressing what we have found on the first part, and also bringing new considerations to the process:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start again with the immigration dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>K</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr   ...     entdepa  entdepd  matflag  biryear   dtaddto  \\\n",
       "0      1.0      HI   ...           G        O        M   1955.0  07202016   \n",
       "1      1.0      TX   ...           G        R        M   1990.0  10222016   \n",
       "2      1.0      FL   ...           G        O        M   1940.0  07052016   \n",
       "3      1.0      CA   ...           G        O        M   1991.0  10272016   \n",
       "4      3.0      NY   ...           Z        K        M   1997.0  07042016   \n",
       "\n",
       "  gender airline        admnum  fltno visatype  \n",
       "0      F      JL  5.658267e+10  00782       WT  \n",
       "1      M     *GA  9.436200e+10  XBLNG       B2  \n",
       "2      M      LH  5.578047e+10  00464       WT  \n",
       "3      M      QR  9.478970e+10  00739       B2  \n",
       "4      F     NaN  4.232257e+10   LAND       WT  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suspecting that the first column corresponds to an id, we will rename the first column to 'Imm_id'\n",
    "\n",
    "Also, we could see all columns were float64 values, when the variables all this column hold, are integers.\n",
    "\n",
    "This is due to Pandas, in order to introduce NaN, which are floats, have to convert the whole column to float.\n",
    "\n",
    "We will fill the NaN with 0 and then convert all float64 columns to integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration.rename({'Unnamed: 0':'Imm_id'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have a column with a very unfortunate name: 'count' can bring future problems for our analysis team, so we change its name, trying to keep its essence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration.rename({'count':'counted'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_columns = list()\n",
    "for column in df_immigration.columns:\n",
    "    if df_immigration[column].dtypes == 'float64':\n",
    "        integer_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_immigration.columns:\n",
    "    if df_immigration[column].dtypes == 'float64':\n",
    "        df_immigration[column] = df_immigration[column].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that our dataframe presents much nicer looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Imm_id</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>209</td>\n",
       "      <td>209</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566</td>\n",
       "      <td>1</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1955</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>JL</td>\n",
       "      <td>56582674633</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>582</td>\n",
       "      <td>582</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>M</td>\n",
       "      <td>1990</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>*GA</td>\n",
       "      <td>94361995930</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>148</td>\n",
       "      <td>112</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551</td>\n",
       "      <td>1</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1940</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>LH</td>\n",
       "      <td>55780468433</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>297</td>\n",
       "      <td>297</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1991</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>QR</td>\n",
       "      <td>94789696030</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550</td>\n",
       "      <td>3</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>K</td>\n",
       "      <td>M</td>\n",
       "      <td>1997</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>42322572633</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Imm_id    cicid  i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  2027561  4084316   2016       4     209     209     HHW    20566        1   \n",
       "1  2171295  4422636   2016       4     582     582     MCA    20567        1   \n",
       "2   589494  1195600   2016       4     148     112     OGG    20551        1   \n",
       "3  2631158  5291768   2016       4     297     297     LOS    20572        1   \n",
       "4  3032257   985523   2016       4     111     111     CHM    20550        3   \n",
       "\n",
       "  i94addr   ...     entdepa  entdepd  matflag  biryear   dtaddto gender  \\\n",
       "0      HI   ...           G        O        M     1955  07202016      F   \n",
       "1      TX   ...           G        R        M     1990  10222016      M   \n",
       "2      FL   ...           G        O        M     1940  07052016      M   \n",
       "3      CA   ...           G        O        M     1991  10272016      M   \n",
       "4      NY   ...           Z        K        M     1997  07042016      F   \n",
       "\n",
       "  airline       admnum  fltno visatype  \n",
       "0      JL  56582674633  00782       WT  \n",
       "1     *GA  94361995930  XBLNG       B2  \n",
       "2      LH  55780468433  00464       WT  \n",
       "3      QR  94789696030  00739       B2  \n",
       "4       0  42322572633   LAND       WT  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still the matter with the dates, so let's address that too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_base_date = '%d-%m-%Y'\n",
    "\n",
    "def transforming_SAS_date(series):\n",
    "    series.fillna(0, inplace = True)\n",
    "    return dt.datetime.strptime('01-01-1960', format_base_date) + series.apply(lambda x: dt.timedelta(days = x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration[['arrdate', 'depdate']] = df_immigration[['arrdate', 'depdate']].apply(transforming_SAS_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Imm_id</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>209</td>\n",
       "      <td>209</td>\n",
       "      <td>HHW</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>1</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1955</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>JL</td>\n",
       "      <td>56582674633</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>582</td>\n",
       "      <td>582</td>\n",
       "      <td>MCA</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>M</td>\n",
       "      <td>1990</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>*GA</td>\n",
       "      <td>94361995930</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>148</td>\n",
       "      <td>112</td>\n",
       "      <td>OGG</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>1</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1940</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>LH</td>\n",
       "      <td>55780468433</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>297</td>\n",
       "      <td>297</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1991</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>QR</td>\n",
       "      <td>94789696030</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>CHM</td>\n",
       "      <td>2016-04-06</td>\n",
       "      <td>3</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>K</td>\n",
       "      <td>M</td>\n",
       "      <td>1997</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>42322572633</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Imm_id    cicid  i94yr  i94mon  i94cit  i94res i94port    arrdate  \\\n",
       "0  2027561  4084316   2016       4     209     209     HHW 2016-04-22   \n",
       "1  2171295  4422636   2016       4     582     582     MCA 2016-04-23   \n",
       "2   589494  1195600   2016       4     148     112     OGG 2016-04-07   \n",
       "3  2631158  5291768   2016       4     297     297     LOS 2016-04-28   \n",
       "4  3032257   985523   2016       4     111     111     CHM 2016-04-06   \n",
       "\n",
       "   i94mode i94addr   ...    entdepa  entdepd  matflag  biryear   dtaddto  \\\n",
       "0        1      HI   ...          G        O        M     1955  07202016   \n",
       "1        1      TX   ...          G        R        M     1990  10222016   \n",
       "2        1      FL   ...          G        O        M     1940  07052016   \n",
       "3        1      CA   ...          G        O        M     1991  10272016   \n",
       "4        3      NY   ...          Z        K        M     1997  07042016   \n",
       "\n",
       "  gender airline       admnum  fltno visatype  \n",
       "0      F      JL  56582674633  00782       WT  \n",
       "1      M     *GA  94361995930  XBLNG       B2  \n",
       "2      M      LH  55780468433  00464       WT  \n",
       "3      M      QR  94789696030  00739       B2  \n",
       "4      F       0  42322572633   LAND       WT  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now go for the demographics dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We face the same problem this the floats as before, but only for some columns, so we are going to address this issue again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics_columns_to_int = ['Male Population', 'Female Population', 'Total Population', 'Number of Veterans', 'Foreign-born']\n",
    "for column in df_demographics_columns_to_int:\n",
    "    df_demographics[column] = df_demographics[column].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we can drop the column 'Number of Veterans', as it holds no interest for our purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics.drop('Number of Veterans', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And change the name of the last column, as in the previous case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics.rename({'count':'counted'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics.rename({'Foreign-born':'Foreignborn'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_demographics['Aux Median Age'] = df_demographics['Median Age']*df_demographics['Total Population']\n",
    "# df_demographics['AuxAverage Household Size'] = df_demographics['Average Household Size']*df_demographics['Total Population']\n",
    "\n",
    "# df_demographics_2 = df_demographics.groupby('State Code').sum().reset_index()\n",
    "# df_demographics_2['Median Age'] = df_demographics_2['Aux Median Age']/df_demographics_2['Total Population']\n",
    "# df_demographics_2['Average Household Size'] = df_demographics_2['AuxAverage Household Size']/df_demographics_2['Total Population']\n",
    "# df_demographics_2 = df_demographics_2['State Code', 'Median Age', 'Male Population', 'Female Population','Total Population', 'Foreignborn', 'Average Household Size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we go for the airports dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name iso_country  \\\n",
       "0   00A       heliport                   Total Rf Heliport          US   \n",
       "1  00AA  small_airport                Aero B Ranch Airport          US   \n",
       "2  00AK  small_airport                        Lowell Field          US   \n",
       "3  00AL  small_airport                        Epps Airpark          US   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport          US   \n",
       "\n",
       "  iso_region  municipality gps_code iata_code local_code  \\\n",
       "0      US-PA      Bensalem      00A       NaN        00A   \n",
       "1      US-KS         Leoti     00AA       NaN       00AA   \n",
       "2      US-AK  Anchor Point     00AK       NaN       00AK   \n",
       "3      US-AL       Harvest     00AL       NaN       00AL   \n",
       "4      US-AR       Newport      NaN       NaN        NaN   \n",
       "\n",
       "                             coordinates  \n",
       "0     -74.93360137939453, 40.07080078125  \n",
       "1                 -101.473911, 38.704022  \n",
       "2            -151.695999146, 59.94919968  \n",
       "3  -86.77030181884766, 34.86479949951172  \n",
       "4                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparantly there is not much to be done, here.\n",
    "\n",
    "Nevertheless, there is one thing we can do: not all of these airports will be of much use for us, so we can reduce the lenght of this dataset by finding which airports are used in our immigration dataset.\n",
    "    \n",
    "For doing so, we will create an airport dictionary by going Regex on the i94_SAS_Labels_Descriptions.SAS, and then checking out dataframe against this dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ALC', 'ANC', 'BAR', 'DAC', 'PIZ', 'DTH', 'EGL', 'FRB', 'HOM', 'HYD', 'JUN', '5KE', 'KET', 'MOS', 'NIK', 'NOM', 'PKC', 'ORI', 'SKA', 'SNP', 'TKI', 'WRA', 'HSV', 'MOB', 'LIA', 'ROG', 'DOU', 'LUK', 'MAP', 'NAC', 'NOG', 'PHO', 'POR', 'SLU', 'SAS', 'TUC', 'YUI', 'AND', 'BUR', 'CAL', 'CAO', 'FRE', 'ICP', 'LNB', 'LOS', 'BFL', 'OAK', 'ONT', 'OTM', 'BLT', 'PSP', 'SAC', 'SLS', 'SDP', 'SFR', 'SNJ', 'SLO', 'SLI', 'SPC', 'SYS', 'SAA', 'STO', 'TEC', 'TRV', 'APA', 'ASE', 'COS', 'DEN', 'DRO', 'BDL', 'BGC', 'GRT', 'HAR', 'NWH', 'NWL', 'TST', 'WAS', 'DOV', 'DVD', 'WLL', 'BOC', 'SRQ', 'CAN', 'DAB', 'FRN', 'FTL', 'FMY', 'FPF', 'HUR', 'GNV', 'JAC', 'KEY', 'LEE', 'MLB', 'MIA', 'APF', 'OPF', 'ORL', 'PAN', 'PEN', 'PCF', 'PEV', 'PSJ', 'SFB', 'SGJ', 'SAU', 'FPR', 'SPE', 'TAM', 'WPB', 'ATL', 'BRU', 'AGS', 'SAV', 'AGA', 'HHW', 'OGG', 'KOA', 'LIH', 'CID', 'DSM', 'BOI', 'EPI', 'IDA', 'PTL', 'SPI', 'CHI', 'DPA', 'PIA', 'RFD', 'UGN', 'GAR', 'HMM', 'INP', 'MRL', 'SBN', 'ICT', 'LEX', 'LOU', 'BTN', 'LKC', 'LAK', 'MLU', 'MGC', 'NOL', 'BOS', 'GLO', 'BED', 'LYN', 'ADW', 'BAL', 'MKG', 'PAX', 'BGM', 'BOO', 'BWM', 'BCK', 'CLS', 'CRB', 'COB', 'EST', 'EPT', 'EPM', 'FOR', 'FTF', 'FTK', 'HML', 'HTM', 'JKM', 'KAL', 'LIM', 'LUB', 'MAD', 'POM', 'RGM', 'SBR', 'SRL', 'SPA', 'VNB', 'VCB', 'AGN', 'ALP', 'BCY', 'DET', 'GRP', 'GRO', 'ISL', 'MRC', 'MRY', 'PTK', 'PHU', 'RBT', 'SAG', 'SSM', 'SCL', 'YIP', 'BAU', 'CAR', 'GTF', 'INL', 'CRA', 'MIC', 'DUL', 'ELY', 'GPM', 'SVC', \"INT'\\t=\\t'INT\", 'LAN', 'MSP', 'LIN', 'NOY', 'PIN', '48Y', 'RAN', 'RST', 'ROS', 'SPM', 'WSB', 'WAR', 'KAN', 'SGF', 'STL', 'WHI', 'WHM', 'GPT', 'GTR', 'GUL', 'PAS', 'JAN', 'BIL', 'BTM', 'CHF', 'CTB', 'CUT', 'DLB', 'EUR', 'BZN', 'FCA', 'GGW', 'GRE', 'HVR', 'HEL', 'LWT', 'MGM', 'OPH', 'PIE', 'RAY', 'ROO', 'SCO', 'SWE', 'TRL', 'TUR', 'WCM', 'CLT', 'FAY', 'MRH', 'FOP', 'GSO', 'RDU', 'SSC', 'WIL', 'AMB', 'ANT', 'CRY', 'DNS', 'FAR', 'FRT', 'GRF', 'HNN', 'HNS', 'MAI', 'MND', 'NEC', 'NOO', 'NRG', 'PEM', 'SAR', 'SHR', 'SJO', 'WAL', 'WHO', 'WND', 'OMA', 'LEB', 'MHT', 'PNH', 'PSM', 'BYO', 'CNJ', 'HOB', 'JER', 'WRI', 'MMU', 'NEW', 'PER', 'ACY', 'ALA', 'ABQ', 'ANP', 'CRL', 'COL', 'CDD', 'DNM', 'LAS', 'LOB', 'RUI', 'STR', 'RNO', 'FLX', 'LVG', 'REN', 'ALB', 'AXB', 'BUF', 'CNH', 'CAP', 'CHM', 'CHT', 'CLA', 'FTC', 'LAG', 'LEW', 'MAS', 'MAG', 'MOO', 'MRR', 'NYC', 'NIA', 'OGD', 'OSW', 'ELM', 'ROC', 'ROU', 'SWF', 'SYR', 'THO', 'TRO', 'WAT', 'HPN', 'WRB', 'YOU', 'AKR', 'ATB', 'CIN', 'CLE', 'CLM', 'LOR', 'MBO', 'SDY', 'TOL', 'OKC', 'TUL', 'AST', 'COO', 'HIO', 'MED', 'NPT', 'POO', 'PUT', 'RDM', 'ERI', 'MDT', 'HSB', 'PHI', 'PIT', 'AGU', 'BQN', 'JCP', 'ENS', 'FAJ', 'HUM', 'JOB', 'MAY', 'PON', 'PSE', 'SAJ', 'VQS', 'PRO', 'PVD', 'CHL', 'CAE', 'GEO', 'GSP', 'GRR', 'MYR', 'SPF', 'HON', 'SAI', 'TYS', 'MEM', 'NSV', 'TRI', 'ADS', 'ADT', 'ANZ', 'AUS', 'BEA', 'BBP', 'SCC', 'BTC', 'BOA', 'BRO', 'CRP', 'DAL', 'DLR', 'DNA', 'EGP', 'ELP', 'FAB', 'FAL', 'FTH', 'AFW', 'FPT', 'GAL', 'HLG', 'HID', 'HOU', 'SGR', 'LLB', 'LCB', 'LRN', 'LAR', 'LSE', 'IND', 'LOI', 'MRS', 'MCA', 'MAF', 'PDN', 'PBB', 'PHR', 'PAR', 'ISB', 'POE', 'PRE', 'PGR', 'RIO', 'ROM', 'SNA', 'SNN', 'VIB', 'YSL', 'CHA', 'CHR', 'CRU', 'FRK', 'STT', 'LGU', 'SLC', 'CHO', 'DAA', 'HOP', 'HEF', 'NWN', 'NOR', 'RCM', 'ABS', 'ABG', 'BEB', 'BEE', 'BRG', 'CNA', 'DER', 'DLV', 'ERC', 'HIG', 'MOR', 'NPV', 'NRT', 'NRN', 'PIV', 'RIF', 'STA', 'SWB', 'WBE', 'ABE', 'ANA', 'BEL', 'BLI', 'BLA', 'BWA', 'CUR', 'DVL', 'EVE', 'FER', 'FRI', 'FWA', 'KLM', 'LAU', 'LON', 'MET', 'MWH', 'NEA', 'NIG', 'OLY', 'ORO', 'PWB', 'PIR', 'PNG', 'PTO', 'SEA', 'SPO', 'SUM', 'TAC', 'PSC', 'VAN', 'AGM', 'BAY', 'GRB', 'MNW', 'MIL', 'MSN', 'CHS', 'CLK', 'BLF', 'CSP', 'XXX', '888', 'UNK', 'CLG', 'EDA', 'YHC', 'HAL', 'MON', 'OTT', 'YXE', 'TOR', 'VCV', 'VIC', 'WIN', 'AMS', 'ARB', 'BAN', 'BEI', 'PEK', 'BDA', 'BOG', 'EZE', 'CUN', 'CRQ', 'MVD', 'DUB', 'FOU', 'FBA', 'MTY', 'HMO', 'GCM', 'GDL', 'HAM', 'ICN', 'IWA', 'CND', 'LAH', 'DUR', 'MAL', 'MDE', 'MEX', 'LHR', 'NBO', 'NAS', 'NCA', 'PTY', 'SPV', 'UIO', 'RIT', 'SNO', 'SLP', 'SAN', 'SRO', 'GRU', 'SHA', 'HIL', 'TOK', 'VER', 'LGW', 'ZZZ', 'CHN', 'CNC', 'MAA', 'AG0', 'BHM', 'BHX', 'CAK', 'FOK', 'LND', 'MAR', 'MLI', 'RIV', 'RME', 'VNY', 'YUM', 'FRG', 'HRL', 'ISP', 'JSJ', 'BUS', 'IAG', 'PHN', 'STN', 'VMB', 'T01', 'PHF', 'DRV', 'FTB', 'GAC', 'GMT', 'JFA', 'JMZ', 'NC8', 'NYL', 'OAI', 'PCW', 'WA5', 'WTR', 'X96', 'XNA', 'YGF', '5T6', '060', 'SP0', 'W55', 'X44', 'AUH', 'RYY', 'SUS', '74S', 'ATW', 'CPX', 'MTH', 'PFN', 'SCH', 'ASI', 'BKF', 'DAY', 'Y62', 'AG', 'BCM', 'DEC', 'PLB', 'CXO', 'JBQ', 'JIG', 'OGS', 'TIW', 'OTS', 'AMT', 'EGE', 'GPI', 'NGL', 'OLM', '.GA', 'CLX', 'CP ', 'FSC', 'NK', 'ADU', 'AKT', 'LIT', 'A2A', 'OSN', 'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'DC', 'FL', 'GA', 'GU', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NC', 'ND', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'OH', 'OK', 'OR', 'PA', 'PR', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VI', 'VA', 'WV', 'WA', 'WI', 'WY', '99'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary of valid i94port codes\n",
    "\n",
    "regex_pattern = re.compile(r'\\'(.*)\\'.*\\'(.*)\\'')\n",
    "i94_airports = dict()\n",
    "with open(SAS_label_descriptions) as label_descriptions:\n",
    "     for line in label_descriptions:\n",
    "         match = regex_pattern.search(line)\n",
    "         if match != None:\n",
    "             i94_airports[match[1]]=[match[2]]\n",
    "            \n",
    "i94_airports.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A previous check on how many of this airports are in our dataframe (we know the right column is 'iata_code' because of some trying and comparisons we decided not to keep, for relevance reasons):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "549"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(i94_airports))\n",
    "len([a for a in list(i94_airports.keys()) if any(df_airports['iata_code'] == a)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we now filter our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airports = df_airports[df_airports['iata_code'].isin(i94_airports.keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AS, in the other direction, also not all values of our dictionary (and, so, our immigration dataset) are to be found in the df_airports dataframe, we create the shorter dictionary with the common airports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "i94_airports_in_df = {a:b for (a,b) in list(i94_airports.items()) if any(df_airports['iata_code'] == a)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could filter the immigration dataset also in search of this common airports, but it wouldn't be good: we loose a fair share of data, and is better to keep it, even though we have not the data of their associated airport."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as we are going to use the \"iata_code\" column for connection with the immigration table, we will look for duplicates in this column (there shouldn't be any):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VQS    2\n",
       "AUS    2\n",
       "HIG    2\n",
       "CLG    2\n",
       "BCK    2\n",
       "MNW    2\n",
       "DLR    2\n",
       "RIV    1\n",
       "GRB    1\n",
       "MIA    1\n",
       "Name: iata_code, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports['iata_code'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we do have some duplicates. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_counts = df_airports['iata_code'].value_counts()\n",
    "\n",
    "list_iata_dup = list(val_counts[val_counts>1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11676</th>\n",
       "      <td>AUS</td>\n",
       "      <td>closed</td>\n",
       "      <td>Austin Robert Mueller Municipal</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KAUS</td>\n",
       "      <td>AUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-97.6997852325, 30.2987223546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26137</th>\n",
       "      <td>KAUS</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Austin Bergstrom International Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Austin</td>\n",
       "      <td>KAUS</td>\n",
       "      <td>AUS</td>\n",
       "      <td>AUS</td>\n",
       "      <td>-97.6698989868164, 30.194499969482422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11637</th>\n",
       "      <td>AU-BCK</td>\n",
       "      <td>closed</td>\n",
       "      <td>[Duplicate] Bolwarra Airport</td>\n",
       "      <td>AU</td>\n",
       "      <td>AU-QLD</td>\n",
       "      <td>Bolwarra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BCK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.169006348, -17.388299942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52989</th>\n",
       "      <td>YBWR</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Bolwarra Airport</td>\n",
       "      <td>AU</td>\n",
       "      <td>AU-QLD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YBWR</td>\n",
       "      <td>BCK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.169006348, -17.388299942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15011</th>\n",
       "      <td>CLG</td>\n",
       "      <td>closed</td>\n",
       "      <td>Coalinga Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CLG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-120.360116959, 36.1580433385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26327</th>\n",
       "      <td>KC80</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>New Coalinga Municipal Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Coalinga</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CLG</td>\n",
       "      <td>C80</td>\n",
       "      <td>-120.29399871826172, 36.16310119628906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17519</th>\n",
       "      <td>DLR</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Dalnerechensk Airport</td>\n",
       "      <td>RU</td>\n",
       "      <td>RU-PRI</td>\n",
       "      <td>Dalnerechensk</td>\n",
       "      <td>UHHD</td>\n",
       "      <td>DLR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.7363, 45.8783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40590</th>\n",
       "      <td>RU-0493</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Dalnerechensk Airport</td>\n",
       "      <td>RU</td>\n",
       "      <td>RU-PRI</td>\n",
       "      <td>Dalnerechensk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DLR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.7363, 45.8783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11651</th>\n",
       "      <td>AU-HIG</td>\n",
       "      <td>closed</td>\n",
       "      <td>[Duplicate] Highbury Airport</td>\n",
       "      <td>AU</td>\n",
       "      <td>AU-QLD</td>\n",
       "      <td>Highbury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HIG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143.145996094, -16.4244003296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53404</th>\n",
       "      <td>YHHY</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Highbury Airport</td>\n",
       "      <td>AU</td>\n",
       "      <td>AU-QLD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YHHY</td>\n",
       "      <td>HIG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143.145996094, -16.4244003296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11658</th>\n",
       "      <td>AU-MNW</td>\n",
       "      <td>closed</td>\n",
       "      <td>[Duplicate] Macdonald Downs Airport</td>\n",
       "      <td>AU</td>\n",
       "      <td>AU-NT</td>\n",
       "      <td>Macdonald Downs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MNW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.199005127, -22.444000244099996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53687</th>\n",
       "      <td>YMDS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Macdonald Downs Airport</td>\n",
       "      <td>AU</td>\n",
       "      <td>AU-NT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YMDS</td>\n",
       "      <td>MNW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.199005127, -22.444000244099996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47792</th>\n",
       "      <td>TJCG</td>\n",
       "      <td>closed</td>\n",
       "      <td>Vieques Airport</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR-U-A</td>\n",
       "      <td>Vieques Island</td>\n",
       "      <td>TJCG</td>\n",
       "      <td>VQS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-65.4226989746, 18.115800857500002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47800</th>\n",
       "      <td>TJVQ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Antonio Rivera Rodriguez Airport</td>\n",
       "      <td>PR</td>\n",
       "      <td>PR-U-A</td>\n",
       "      <td>Vieques Island</td>\n",
       "      <td>TJVQ</td>\n",
       "      <td>VQS</td>\n",
       "      <td>VQS</td>\n",
       "      <td>-65.493598938, 18.1347999573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ident           type                                    name  \\\n",
       "11676      AUS         closed         Austin Robert Mueller Municipal   \n",
       "26137     KAUS  large_airport  Austin Bergstrom International Airport   \n",
       "11637   AU-BCK         closed            [Duplicate] Bolwarra Airport   \n",
       "52989     YBWR  small_airport                        Bolwarra Airport   \n",
       "15011      CLG         closed                        Coalinga Airport   \n",
       "26327     KC80  small_airport          New Coalinga Municipal Airport   \n",
       "17519      DLR  small_airport                   Dalnerechensk Airport   \n",
       "40590  RU-0493  small_airport                   Dalnerechensk Airport   \n",
       "11651   AU-HIG         closed            [Duplicate] Highbury Airport   \n",
       "53404     YHHY  small_airport                        Highbury Airport   \n",
       "11658   AU-MNW         closed     [Duplicate] Macdonald Downs Airport   \n",
       "53687     YMDS  small_airport                 Macdonald Downs Airport   \n",
       "47792     TJCG         closed                         Vieques Airport   \n",
       "47800     TJVQ  small_airport        Antonio Rivera Rodriguez Airport   \n",
       "\n",
       "      iso_country iso_region     municipality gps_code iata_code local_code  \\\n",
       "11676          US      US-TX              NaN     KAUS       AUS        NaN   \n",
       "26137          US      US-TX           Austin     KAUS       AUS        AUS   \n",
       "11637          AU     AU-QLD         Bolwarra      NaN       BCK        NaN   \n",
       "52989          AU     AU-QLD              NaN     YBWR       BCK        NaN   \n",
       "15011          US      US-CA              NaN      NaN       CLG        NaN   \n",
       "26327          US      US-CA         Coalinga      NaN       CLG        C80   \n",
       "17519          RU     RU-PRI    Dalnerechensk     UHHD       DLR        NaN   \n",
       "40590          RU     RU-PRI    Dalnerechensk      NaN       DLR        NaN   \n",
       "11651          AU     AU-QLD         Highbury      NaN       HIG        NaN   \n",
       "53404          AU     AU-QLD              NaN     YHHY       HIG        NaN   \n",
       "11658          AU      AU-NT  Macdonald Downs      NaN       MNW        NaN   \n",
       "53687          AU      AU-NT              NaN     YMDS       MNW        NaN   \n",
       "47792          PR     PR-U-A   Vieques Island     TJCG       VQS        NaN   \n",
       "47800          PR     PR-U-A   Vieques Island     TJVQ       VQS        VQS   \n",
       "\n",
       "                                  coordinates  \n",
       "11676           -97.6997852325, 30.2987223546  \n",
       "26137   -97.6698989868164, 30.194499969482422  \n",
       "11637            144.169006348, -17.388299942  \n",
       "52989            144.169006348, -17.388299942  \n",
       "15011           -120.360116959, 36.1580433385  \n",
       "26327  -120.29399871826172, 36.16310119628906  \n",
       "17519                       133.7363, 45.8783  \n",
       "40590                       133.7363, 45.8783  \n",
       "11651           143.145996094, -16.4244003296  \n",
       "53404           143.145996094, -16.4244003296  \n",
       "11658      135.199005127, -22.444000244099996  \n",
       "53687      135.199005127, -22.444000244099996  \n",
       "47792      -65.4226989746, 18.115800857500002  \n",
       "47800            -65.493598938, 18.1347999573  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports[df_airports['iata_code'].isin(list_iata_dup)].sort_values('iata_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this phenomenom is due to several airports having been built again, so there is an old and a new airport for the same IATA code.\n",
    "\n",
    "There is one exception: Dalnerechensk Airport, not marked neither as closed nor as a duplicate.\n",
    "\n",
    "We will drop the old airports marked as \"closed\", and also this one airport, by its identity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airports = df_airports[~((df_airports['iata_code'].isin(list_iata_dup)) & (df_airports['type'] == 'closed'))]\n",
    "df_airports = df_airports[df_airports['ident'] != 'RU-0493']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, finally, our latest transformation is to separate the longitude and latitude columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airports['longitude'] = df_airports['coordinates'].apply(lambda x: x.split(',')[0])\n",
    "df_airports['latitude'] = df_airports['coordinates'].apply(lambda x: x.split(',')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airports.drop('coordinates', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>57A</td>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>Tokeen Seaplane Base</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Tokeen</td>\n",
       "      <td>57A</td>\n",
       "      <td>TKI</td>\n",
       "      <td>57A</td>\n",
       "      <td>-133.32699585</td>\n",
       "      <td>55.9370994568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6731</th>\n",
       "      <td>5Z9</td>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>Lake Brooks Seaplane Base</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Katmai National Park</td>\n",
       "      <td>5Z9</td>\n",
       "      <td>BKF</td>\n",
       "      <td>5Z9</td>\n",
       "      <td>-155.77699279785</td>\n",
       "      <td>58.554798126221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8976</th>\n",
       "      <td>89NY</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Maxson Airfield</td>\n",
       "      <td>US</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>Alexandria Bay</td>\n",
       "      <td>89NY</td>\n",
       "      <td>AXB</td>\n",
       "      <td>89NY</td>\n",
       "      <td>-75.90034</td>\n",
       "      <td>44.312002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10441</th>\n",
       "      <td>AGGF</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Fera/Maringe Airport</td>\n",
       "      <td>SB</td>\n",
       "      <td>SB-IS</td>\n",
       "      <td>Fera Island</td>\n",
       "      <td>AGGF</td>\n",
       "      <td>FRE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159.576996</td>\n",
       "      <td>-8.1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10695</th>\n",
       "      <td>ANZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Angus Downs Airport</td>\n",
       "      <td>AU</td>\n",
       "      <td>AU-NT</td>\n",
       "      <td>Angus Downs Station</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.2748</td>\n",
       "      <td>-25.0325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ident           type                       name iso_country iso_region  \\\n",
       "6055    57A  seaplane_base       Tokeen Seaplane Base          US      US-AK   \n",
       "6731    5Z9  seaplane_base  Lake Brooks Seaplane Base          US      US-AK   \n",
       "8976   89NY  small_airport            Maxson Airfield          US      US-NY   \n",
       "10441  AGGF  small_airport       Fera/Maringe Airport          SB      SB-IS   \n",
       "10695   ANZ  small_airport        Angus Downs Airport          AU      AU-NT   \n",
       "\n",
       "               municipality gps_code iata_code local_code         longitude  \\\n",
       "6055                 Tokeen      57A       TKI        57A     -133.32699585   \n",
       "6731   Katmai National Park      5Z9       BKF        5Z9  -155.77699279785   \n",
       "8976         Alexandria Bay     89NY       AXB       89NY         -75.90034   \n",
       "10441           Fera Island     AGGF       FRE        NaN        159.576996   \n",
       "10695   Angus Downs Station      NaN       ANZ        NaN          132.2748   \n",
       "\n",
       "               latitude  \n",
       "6055      55.9370994568  \n",
       "6731    58.554798126221  \n",
       "8976          44.312002  \n",
       "10441           -8.1075  \n",
       "10695          -25.0325  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as for temperatures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Ã…rhus   \n",
       "1  1743-12-01                 NaN                            NaN  Ã…rhus   \n",
       "2  1744-01-01                 NaN                            NaN  Ã…rhus   \n",
       "3  1744-02-01                 NaN                            NaN  Ã…rhus   \n",
       "4  1744-03-01                 NaN                            NaN  Ã…rhus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperatures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There weren't many nulls, so we drop them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temperatures.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our 'dt' column is a string, and we can see that our dates go back in time to ancient times.\n",
    "\n",
    "We don't need this data, we can keep just from 2010 to present date.\n",
    "\n",
    "That's what we will do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98312</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>28.242</td>\n",
       "      <td>0.571</td>\n",
       "      <td>Agartala</td>\n",
       "      <td>India</td>\n",
       "      <td>23.31N</td>\n",
       "      <td>91.75E</td>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98313</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>27.854</td>\n",
       "      <td>0.747</td>\n",
       "      <td>Agartala</td>\n",
       "      <td>India</td>\n",
       "      <td>23.31N</td>\n",
       "      <td>91.75E</td>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98314</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>29.664</td>\n",
       "      <td>0.575</td>\n",
       "      <td>Agartala</td>\n",
       "      <td>India</td>\n",
       "      <td>23.31N</td>\n",
       "      <td>91.75E</td>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98315</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>28.926</td>\n",
       "      <td>0.425</td>\n",
       "      <td>Agartala</td>\n",
       "      <td>India</td>\n",
       "      <td>23.31N</td>\n",
       "      <td>91.75E</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98316</th>\n",
       "      <td>2013-08-01</td>\n",
       "      <td>28.381</td>\n",
       "      <td>0.653</td>\n",
       "      <td>Agartala</td>\n",
       "      <td>India</td>\n",
       "      <td>23.31N</td>\n",
       "      <td>91.75E</td>\n",
       "      <td>2013-08-01</td>\n",
       "      <td>8</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dt  AverageTemperature  AverageTemperatureUncertainty  \\\n",
       "98312  2013-04-01              28.242                          0.571   \n",
       "98313  2013-05-01              27.854                          0.747   \n",
       "98314  2013-06-01              29.664                          0.575   \n",
       "98315  2013-07-01              28.926                          0.425   \n",
       "98316  2013-08-01              28.381                          0.653   \n",
       "\n",
       "           City Country Latitude Longitude       date  month  year  day  \n",
       "98312  Agartala   India   23.31N    91.75E 2013-04-01      4  2013    1  \n",
       "98313  Agartala   India   23.31N    91.75E 2013-05-01      5  2013    1  \n",
       "98314  Agartala   India   23.31N    91.75E 2013-06-01      6  2013    1  \n",
       "98315  Agartala   India   23.31N    91.75E 2013-07-01      7  2013    1  \n",
       "98316  Agartala   India   23.31N    91.75E 2013-08-01      8  2013    1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_format_df_temp = '%Y-%m-%d'\n",
    "\n",
    "df_temperatures['date'] = df_temperatures['dt'].apply(lambda x: dt.datetime.strptime(x, date_format_df_temp))\n",
    "df_temperatures['month'] = df_temperatures['date'].apply(lambda x: x.month)\n",
    "df_temperatures['year'] = df_temperatures['date'].apply(lambda x: x.year)\n",
    "df_temperatures['day'] = df_temperatures['date'].apply(lambda x: x.day)\n",
    "df_temperatures[df_temperatures['year']>=2008].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have record only up to September of 2013. We will create then a dataset of temperatures from 2000 on, and now we will bring in all our data and filter it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3074</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>3.065</td>\n",
       "      <td>0.372</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>3.724</td>\n",
       "      <td>0.241</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>3.976</td>\n",
       "      <td>0.296</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>8.321</td>\n",
       "      <td>0.221</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078</th>\n",
       "      <td>2000-05-01</td>\n",
       "      <td>13.567</td>\n",
       "      <td>0.253</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>2000-05-01</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "3074  2000-01-01               3.065                          0.372  Ã…rhus   \n",
       "3075  2000-02-01               3.724                          0.241  Ã…rhus   \n",
       "3076  2000-03-01               3.976                          0.296  Ã…rhus   \n",
       "3077  2000-04-01               8.321                          0.221  Ã…rhus   \n",
       "3078  2000-05-01              13.567                          0.253  Ã…rhus   \n",
       "\n",
       "      Country Latitude Longitude       date  year  \n",
       "3074  Denmark   57.05N    10.33E 2000-01-01  2000  \n",
       "3075  Denmark   57.05N    10.33E 2000-02-01  2000  \n",
       "3076  Denmark   57.05N    10.33E 2000-03-01  2000  \n",
       "3077  Denmark   57.05N    10.33E 2000-04-01  2000  \n",
       "3078  Denmark   57.05N    10.33E 2000-05-01  2000  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_reading_obj = pd.read_csv(temperatures_path, chunksize=100000)\n",
    "\n",
    "df_temperatures_total = pd.DataFrame()\n",
    "\n",
    "for i, chunk in enumerate(temp_reading_obj):\n",
    "    chunk.dropna(inplace = True)\n",
    "    chunk['date'] = chunk['dt'].apply(lambda x: dt.datetime.strptime(x, date_format_df_temp))\n",
    "    chunk['year'] = chunk['date'].apply(lambda x: x.year)\n",
    "    \n",
    "    if i == 0:\n",
    "        df_temperatures_total = chunk[chunk['year']>=2000]\n",
    "    else:\n",
    "        df_temperatures_total.append(chunk[chunk['year']>=2000])\n",
    "    \n",
    "df_temperatures_total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't seem to be the case, but in case there are more than one point of data per month, we will group by those values and take the mean. We will also calculate the average unvertainty and will calculate averge temperatures and uncertainty values for the year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temperatures_total['month'] = df_temperatures_total['date'].apply(lambda x: x.month)\n",
    "df_temperatures_total_gr = df_temperatures_total.groupby(['month', 'year', 'City', 'Country']).mean().reset_index().sort_values(['City', 'Country', 'year', 'month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temperatures_total_gr_av = df_temperatures_total_gr.groupby(['City', 'Country']).mean().reset_index().sort_values(['City', 'Country', 'year'])[['City', 'Country', 'AverageTemperature']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temperatures_total_gr_av.rename({'AverageTemperature':'AvgTotal'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temperatures_total_gr = pd.merge(df_temperatures_total_gr, df_temperatures_total_gr_av, on=['City', 'Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>AvgTotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>A CoruÃ±a</td>\n",
       "      <td>Spain</td>\n",
       "      <td>7.468</td>\n",
       "      <td>0.318</td>\n",
       "      <td>14.034128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>A CoruÃ±a</td>\n",
       "      <td>Spain</td>\n",
       "      <td>11.199</td>\n",
       "      <td>0.429</td>\n",
       "      <td>14.034128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>A CoruÃ±a</td>\n",
       "      <td>Spain</td>\n",
       "      <td>12.242</td>\n",
       "      <td>0.501</td>\n",
       "      <td>14.034128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2000</td>\n",
       "      <td>A CoruÃ±a</td>\n",
       "      <td>Spain</td>\n",
       "      <td>10.431</td>\n",
       "      <td>0.379</td>\n",
       "      <td>14.034128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>A CoruÃ±a</td>\n",
       "      <td>Spain</td>\n",
       "      <td>15.149</td>\n",
       "      <td>0.457</td>\n",
       "      <td>14.034128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  year      City Country  AverageTemperature  \\\n",
       "0      1  2000  A CoruÃ±a   Spain               7.468   \n",
       "1      2  2000  A CoruÃ±a   Spain              11.199   \n",
       "2      3  2000  A CoruÃ±a   Spain              12.242   \n",
       "3      4  2000  A CoruÃ±a   Spain              10.431   \n",
       "4      5  2000  A CoruÃ±a   Spain              15.149   \n",
       "\n",
       "   AverageTemperatureUncertainty   AvgTotal  \n",
       "0                          0.318  14.034128  \n",
       "1                          0.429  14.034128  \n",
       "2                          0.501  14.034128  \n",
       "3                          0.379  14.034128  \n",
       "4                          0.457  14.034128  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperatures_total_gr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will treat the df_countries DataFrame.\n",
    "\n",
    "We are interested in the GDP per capita mean value of last years, and the average % increase or decline of such value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>year</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>2010</td>\n",
       "      <td>23512.602600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>2010</td>\n",
       "      <td>543.303042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>2010</td>\n",
       "      <td>3587.883798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>2010</td>\n",
       "      <td>4094.350334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>AND</td>\n",
       "      <td>2010</td>\n",
       "      <td>40852.666780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Name Country Code  year         value\n",
       "0        Aruba          ABW  2010  23512.602600\n",
       "1  Afghanistan          AFG  2010    543.303042\n",
       "2       Angola          AGO  2010   3587.883798\n",
       "3      Albania          ALB  2010   4094.350334\n",
       "4      Andorra          AND  2010  40852.666780"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>max_year</th>\n",
       "      <th>GDP_capita_max_year</th>\n",
       "      <th>min_year</th>\n",
       "      <th>GDP_capita_min_year</th>\n",
       "      <th>%_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>2019</td>\n",
       "      <td>641.871479</td>\n",
       "      <td>2010</td>\n",
       "      <td>502.115487</td>\n",
       "      <td>2.765984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>2019</td>\n",
       "      <td>5352.857411</td>\n",
       "      <td>2010</td>\n",
       "      <td>3952.801215</td>\n",
       "      <td>3.426348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZA</td>\n",
       "      <td>2019</td>\n",
       "      <td>5592.257099</td>\n",
       "      <td>2010</td>\n",
       "      <td>3946.443977</td>\n",
       "      <td>3.948956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>ASM</td>\n",
       "      <td>2018</td>\n",
       "      <td>11843.331180</td>\n",
       "      <td>2010</td>\n",
       "      <td>10271.224520</td>\n",
       "      <td>1.796174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>AND</td>\n",
       "      <td>2019</td>\n",
       "      <td>43335.328860</td>\n",
       "      <td>2010</td>\n",
       "      <td>35762.523070</td>\n",
       "      <td>2.157020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country Name Country Code  max_year  GDP_capita_max_year  min_year  \\\n",
       "0     Afghanistan          AFG      2019           641.871479      2010   \n",
       "1         Albania          ALB      2019          5352.857411      2010   \n",
       "2         Algeria          DZA      2019          5592.257099      2010   \n",
       "3  American Samoa          ASM      2018         11843.331180      2010   \n",
       "4         Andorra          AND      2019         43335.328860      2010   \n",
       "\n",
       "   GDP_capita_min_year  %_change  \n",
       "0           502.115487  2.765984  \n",
       "1          3952.801215  3.426348  \n",
       "2          3946.443977  3.948956  \n",
       "3         10271.224520  1.796174  \n",
       "4         35762.523070  2.157020  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_df1 = df_countries.dropna().groupby(['Country Name', 'Country Code']).max().reset_index()\n",
    "aux_df2 = df_countries.dropna().groupby(['Country Name', 'Country Code']).min().reset_index()\n",
    "\n",
    "aux_df1.rename({'year':'max_year', 'value':'GDP_capita_max_year'}, axis = 1, inplace = True)\n",
    "\n",
    "aux_df1[['min_year', 'GDP_capita_min_year']] = aux_df2[['year', 'value']]\n",
    "aux_df1['max_year'] = aux_df1['max_year'].astype('int')\n",
    "aux_df1['min_year'] = aux_df1['min_year'].astype('int')\n",
    "\n",
    "aux_df1['%_change'] = ((aux_df1['GDP_capita_max_year'] / aux_df1['GDP_capita_min_year'])**(1/(aux_df1['max_year'] - aux_df1['min_year'])) -1) * 100\n",
    "aux_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>avg_GDP_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>4502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZA</td>\n",
       "      <td>4675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>ASM</td>\n",
       "      <td>11220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>AND</td>\n",
       "      <td>39860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country Name Country Code  avg_GDP_capita\n",
       "0     Afghanistan          AFG             574\n",
       "1         Albania          ALB            4502\n",
       "2         Algeria          DZA            4675\n",
       "3  American Samoa          ASM           11220\n",
       "4         Andorra          AND           39860"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_df3 = df_countries.groupby(['Country Name', 'Country Code']).mean().round().dropna().astype('int').reset_index()\n",
    "aux_df3.rename({'value':'avg_GDP_capita'}, axis = 1, inplace = True)\n",
    "aux_df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countries_final = pd.merge(aux_df3, aux_df1, on = ['Country Name', 'Country Code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save this results in some csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "immigration_csv_path = './treated/immigration_sample_treated.csv'\n",
    "df_immigration.to_csv(immigration_csv_path, sep = \";\", encoding=\"ISO-8859-1\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_csv_path = './treated/airports_treated.csv'\n",
    "df_airports.to_csv(airports_csv_path, sep = \";\", encoding=\"ISO-8859-1\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_csv_path = './treated/demographics_treated.csv'\n",
    "df_demographics.to_csv(demographics_csv_path, sep = \";\", encoding=\"ISO-8859-1\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures_csv_path = './treated/temperatures_treated.csv'\n",
    "df_temperatures_total_gr.to_csv(temperatures_csv_path, sep = \";\", encoding=\"ISO-8859-1\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_csv_path = './treated/countries_treated.csv'\n",
    "df_countries_final.to_csv(countries_csv_path, sep = \";\", encoding=\"ISO-8859-1\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Steps (Spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the immigration files, we have undertaken this process with pandas and small ammounts of data using sample files, but this process, for the bigger files, should be accomplished with Spark.\n",
    "\n",
    "We should, then, recollect all the cleaning steps we have done in pandas, and translate them into Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1.897628485E9| null|      B2|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the Spark session and uploading a file:\n",
    "\n",
    "spark = SparkSession.builder.config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\").enableHiveSupport().getOrCreate()\n",
    "spark_df_immigration_trial = spark.read.format('com.github.saurfang.sas.spark').load(SAS_immigration)\n",
    "spark_df_immigration_trial.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we dropped 4 columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_immigration_columns_with_nulls:\n",
    "    spark_df_immigration_trial = spark_df_immigration_trial.drop(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we renamed the columns 'Unnamed: 0' (curiously enough, it is not present when loading the file in Spark) and 'count', and filled the NA with zeroes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df_immigration_trial = spark_df_immigration_trial.withColumnRenamed ('Unnamed: 0','Imm_id')\n",
    "spark_df_immigration_trial = spark_df_immigration_trial.withColumnRenamed ('count', 'counted')\n",
    "spark_df_immigration_trial = spark_df_immigration_trial.na.fill(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't perform then a filter by the values in the i94_airports dictionary, but we will perform such check now, and see how many columns are there afterwars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df_immigration_trial.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df_immigration_trial_filtered = spark_df_immigration_trial.filter(spark_df_immigration_trial['i94port'].isin(list(i94_airports.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096281"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df_immigration_trial_filtered.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we keep most of our data.\n",
    "\n",
    "Then, we changed the data types, from floats to integers, in all columns (as no data was supposed to be float):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_dtypes = spark_df_immigration_trial_filtered.dtypes\n",
    "columns_as_double = [i[0] for i in columns_dtypes if i[1] == 'double']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_columns_as_type(df, column_list, var_type):\n",
    "    \n",
    "    for column in df.columns:\n",
    "        if column in column_list:\n",
    "            df = df.withColumn(column, df[column].cast(IntegerType()))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df_immigration_trial_filtered = cast_columns_as_type(spark_df_immigration_trial_filtered, columns_as_double, IntegerType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cicid', 'int'),\n",
       " ('i94yr', 'int'),\n",
       " ('i94mon', 'int'),\n",
       " ('i94cit', 'int'),\n",
       " ('i94res', 'int'),\n",
       " ('i94port', 'string'),\n",
       " ('arrdate', 'int'),\n",
       " ('i94mode', 'int'),\n",
       " ('i94addr', 'string'),\n",
       " ('depdate', 'int'),\n",
       " ('i94bir', 'int'),\n",
       " ('i94visa', 'int'),\n",
       " ('counted', 'int'),\n",
       " ('dtadfile', 'string'),\n",
       " ('entdepa', 'string'),\n",
       " ('entdepd', 'string'),\n",
       " ('matflag', 'string'),\n",
       " ('biryear', 'int'),\n",
       " ('dtaddto', 'string'),\n",
       " ('gender', 'string'),\n",
       " ('airline', 'string'),\n",
       " ('admnum', 'int'),\n",
       " ('fltno', 'string'),\n",
       " ('visatype', 'string')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df_immigration_trial_filtered.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we took the 'arrdate' and 'depdate' columns and changed them from integers to datatime objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spark_transforming_SAS_date(x):\n",
    "    return dt.datetime.strptime('01-01-1960', '%d-%m-%Y') + dt.timedelta(days = x)\n",
    "\n",
    "udf_spark_transforming_SAS_date = udf(spark_transforming_SAS_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df_immigration_trial_filtered = spark_df_immigration_trial_filtered.withColumn('arrdate', udf_spark_transforming_SAS_date('arrdate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df_immigration_trial_filtered = spark_df_immigration_trial_filtered.withColumn('depdate', udf_spark_transforming_SAS_date('depdate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+------+------+-------+--------------------+-------+-------+--------------------+------+-------+-------+--------+-------+-------+-------+-------+--------+------+-------+----------+-----+--------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|             arrdate|i94mode|i94addr|             depdate|i94bir|i94visa|counted|dtadfile|entdepa|entdepd|matflag|biryear| dtaddto|gender|airline|    admnum|fltno|visatype|\n",
      "+-----+-----+------+------+------+-------+--------------------+-------+-------+--------------------+------+-------+-------+--------+-------+-------+-------+-------+--------+------+-------+----------+-----+--------+\n",
      "|    6| 2016|     4|   692|   692|    XXX|java.util.Gregori...|      0|   null|java.util.Gregori...|    37|      2|      1|    null|      T|   null|   null|   1979|10282016|  null|   null|1897628485| null|      B2|\n",
      "|    7| 2016|     4|   254|   276|    ATL|java.util.Gregori...|      1|     AL|java.util.Gregori...|    25|      3|      1|20130811|      G|   null|   null|   1991|     D/S|     M|   null|2147483647|00296|      F1|\n",
      "|   15| 2016|     4|   101|   101|    WAS|java.util.Gregori...|      1|     MI|java.util.Gregori...|    55|      2|      1|20160401|      T|      O|      M|   1961|09302016|     M|     OS| 666643185|   93|      B2|\n",
      "|   16| 2016|     4|   101|   101|    NYC|java.util.Gregori...|      1|     MA|java.util.Gregori...|    28|      2|      1|20160401|      O|      O|      M|   1988|09302016|  null|     AA|2147483647|00199|      B2|\n",
      "|   17| 2016|     4|   101|   101|    NYC|java.util.Gregori...|      1|     MA|java.util.Gregori...|     4|      2|      1|20160401|      O|      O|      M|   2012|09302016|  null|     AA|2147483647|00199|      B2|\n",
      "+-----+-----+------+------+------+-------+--------------------+-------+-------+--------------------+------+-------+-------+--------+-------+-------+-------+-------+--------+------+-------+----------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df_immigration_trial_filtered.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all these operations we would end our data cleaning in Spark for the large immigration files.\n",
    "\n",
    "The rest of them can be treated in Python, justified by their size.\n",
    "\n",
    "The problem would start when bringing all together, as this immigration files are too big to fit comfortably in a regular SQL database and be used nicely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "At this moment, this is our situation (we will be calling it POINT1):\n",
    "\n",
    "<img src=\"IMAGES/DATABASE_MODEL_INITIALLY.png\" style=\"width: 800px;\" />\n",
    "\n",
    "we have cleaned our information, but we have not dealt with its structure. \n",
    "\n",
    "That is what we are going to do now.\n",
    "\n",
    "The main purpose of this pipeline is to perform machine learning analysis afterwards. So it will be useful to have a big table with all the information readily available. At the same time, adjacent tables can be useful for the Data Scientists to gather more data just by performing one \"JOIN\" operation. So, our model of choice will be a sort of star schema, with one immigration facts table in which we will present the most relevant information to the viewer, and the rest of the tables as they are, linked to our immigration facts table.\n",
    "\n",
    "From all the information contained in our tables, we are going to perform several transformations to end with the following schema:\n",
    "\n",
    "\n",
    "<img src=\"IMAGES/DATABASE_MODEL_END.png\" style=\"width: 800px;\" />\n",
    "\n",
    "\n",
    "We will be referring this situation as POINT2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "We have seen the steps needed to perform the cleaning of our data.\n",
    "\n",
    "These are the steps required to get from POINT1 to POINT2:\n",
    "\n",
    "1) Transform the airports_treated and immigration_treated tables to hold common codes as explained in the **NOTE**. We will name these tables airports_treated_code and immigration_treated_code.\n",
    "\n",
    "2) We want to check directly some information from the immigration table with the demographics table, but we find that it is complicated to tell which is the specfic location the travaler is going to, but at the same time, we have the state code for the state they are staying at. So, the second stage will be grouping the demographics table by State. This table will be called demographics_treated_grouped.\n",
    "\n",
    "3) Create the immigration_facts_table from the immigration_treated_code, performing the required JOINs to other tables.\n",
    "\n",
    "* **NOTE 1:** When reaching this point we find a problem in regards to defining the relationship between the country table and the immigration and airport tables, as they have different codes assigned for their countries columns. In response to that, we have created a country_codes table, that we stored as a csv under the folder \"AUXILIARY\". The information comes originally from https://www.iban.com/country-codes, and to that info we have added the i94 country codes manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did the process with the samples in a MySQL database. Due to the huge ammount of data to be treated within the immigration dataset, we decide to go with Spark here.\n",
    "We will load Spark DataFrames from the auxiliary csv files that generated earlier, creating Temporary Views of our tables to run SQL code on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the rest of the data from our csv files:\n",
    "\n",
    "aux_countries = './Auxiliary/country_codes.csv'\n",
    "\n",
    "spark_df_airports = spark.read.option(\"header\",True).csv(airports_csv_path, sep=\";\", encoding = 'ISO-8859-1')\n",
    "spark_df_demographics = spark.read.option(\"header\",True).csv(demographics_csv_path, sep=\";\", encoding = 'ISO-8859-1')\n",
    "spark_df_temperatures = spark.read.option(\"header\",True).csv(temperatures_csv_path, sep=\";\", encoding = 'ISO-8859-1')\n",
    "spark_df_countries = spark.read.option(\"header\",True).csv(countries_csv_path, sep=\";\", encoding = 'ISO-8859-1')\n",
    "spark_df_aux = spark.read.option(\"header\",True).csv(aux_countries, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the required temporal views:\n",
    "\n",
    "spark_df_immigration_trial_filtered.createOrReplaceTempView(\"immigration_treated\")\n",
    "spark_df_airports.createOrReplaceTempView(\"airports_treated\")\n",
    "spark_df_demographics.createOrReplaceTempView(\"demographics_treated\")\n",
    "spark_df_temperatures.createOrReplaceTempView(\"temperatures_treated\")\n",
    "spark_df_countries.createOrReplaceTempView(\"countries_treated\")\n",
    "spark_df_aux.createOrReplaceTempView(\"country_codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query is for creating the airports_treated_code described above, the table of airports with the countries codes added:\n",
    "\n",
    "query_1 = \"\"\"SELECT a.*, b.CountryCode, b.i94cntyl\n",
    "    FROM airports_treated AS a\n",
    "    JOIN country_codes AS b\n",
    "    ON a.iso_country = b.iso_country\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df_airports_treated_code = spark.sql(query_1)\n",
    "spark_df_airports_treated_code.createOrReplaceTempView(\"airports_treated_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query is for adding the country codes to the immigration table:\n",
    "\n",
    "query_2 =\"\"\"SELECT a.*,\n",
    "        b.CountryCode AS cit_CountryCode, \n",
    "        b.iso_country AS cit_iso_country,\n",
    "        c.CountryCode AS res_CountryCode, \n",
    "        c.iso_country AS res_iso_country\n",
    "    FROM immigration_treated AS a\n",
    "    JOIN country_codes AS b\n",
    "    ON a.i94cit = b.i94cntyl\n",
    "    JOIN country_codes AS c\n",
    "    ON a.i94res = c.i94cntyl\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df_immigration_sample_treated_code = spark.sql(query_2)\n",
    "spark_df_immigration_sample_treated_code.createOrReplaceTempView(\"immigration_sample_treated_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query is for grouping the demographics data by State, so we will be able to correctly link it to the immigration table to create of facts table:\n",
    "\n",
    "# This is the old query comming from SQL:\n",
    "\n",
    "query_3_old = \"\"\"SELECT State, State_Code,\n",
    "    SUM(Median_Age)/SUM(Total_Population) AS Median_Age,\n",
    "    SUM(Male_Population) AS Male_Population,\n",
    "    SUM(Female_Population) AS Female_Population,\n",
    "    SUM(Total_Population) AS Total_Population,\n",
    "    SUM(Foreignborn) AS Foreignborn,\n",
    "    SUM(Average_Household_Size)/SUM(Total_Population) AS Average_Household_Size,\n",
    "    SUM(Foreignborn)/SUM(Total_Population) AS percent_foreignborn\n",
    "FROM demographics_treated\n",
    "GROUP BY State_Code\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query is for grouping the demographics data by State, so we will be able to correctly link it to the immigration table to create of facts table:\n",
    "\n",
    "# Valid query:\n",
    "\n",
    "query_3_2 = \"\"\"SELECT FIRST(State) AS State, \n",
    "        `State Code`,\n",
    "        SUM(`Median Age`)/SUM(`Total Population`) AS Median_Age,\n",
    "        SUM(`Male Population`) AS Male_Population,\n",
    "        SUM(`Female Population`) AS Female_Population,\n",
    "        SUM(`Total Population`) AS Total_Population,\n",
    "        SUM(Foreignborn) AS Foreignborn,\n",
    "        SUM(`Average Household Size`)/SUM(`Total Population`) AS Average_Household_Size,\n",
    "        SUM(Foreignborn)/SUM(`Total Population`) AS Percent_Foreignborn\n",
    "    FROM demographics_treated\n",
    "    GROUP BY `State Code`\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df_demographics_treated_code = spark.sql(query_3_2)\n",
    "spark_df_demographics_treated_code.createOrReplaceTempView(\"demographics_treated_grouped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the query with which we create our facts table:\n",
    "\n",
    "query_4 = \"\"\"SELECT a.cicid,\n",
    "        a.biryear,\n",
    "        a.gender,\n",
    "        a.i94yr,\n",
    "        a.i94mon,\n",
    "        a.i94cit,\n",
    "        a.cit_CountryCode,\n",
    "        a.cit_iso_country,\n",
    "        a.i94res,\n",
    "        a.res_CountryCode,\n",
    "        a.res_iso_country,\n",
    "        a.i94port,\n",
    "        d.CountryCode AS CountryAirport,\n",
    "        a.arrdate,\n",
    "        a.i94mode,\n",
    "        a.i94addr,\n",
    "        c.Percent_Foreignborn,\n",
    "        a.depdate,\n",
    "        a.i94bir,\n",
    "        a.i94visa,\n",
    "        a.visatype,\n",
    "        b.avg_GDP_capita AS res_avg_GDP_capita,\n",
    "        b.`%_change` AS res_GDPcapita_annual_change\n",
    "\n",
    "    FROM immigration_sample_treated_code AS a\n",
    "    LEFT JOIN countries_treated AS b\n",
    "    ON a.res_CountryCode = b.`Country Code`\n",
    "    LEFT JOIN demographics_treated_grouped AS c\n",
    "    ON a.i94addr = c.`State Code`\n",
    "    LEFT JOIN airports_treated_code AS d\n",
    "    ON a.i94port = d.iata_code\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df_immigration_facts = spark.sql(query_4)\n",
    "spark_df_immigration_facts.createOrReplaceTempView(\"immigration_facts_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-----+------+------+---------------+---------------+------+---------------+---------------+-------+--------------+--------------------+-------+-------+-------------------+--------------------+------+-------+--------+------------------+---------------------------+\n",
      "| cicid|biryear|gender|i94yr|i94mon|i94cit|cit_CountryCode|cit_iso_country|i94res|res_CountryCode|res_iso_country|i94port|CountryAirport|             arrdate|i94mode|i94addr|Percent_Foreignborn|             depdate|i94bir|i94visa|visatype|res_avg_GDP_capita|res_GDPcapita_annual_change|\n",
      "+------+-------+------+-----+------+------+---------------+---------------+------+---------------+---------------+-------+--------------+--------------------+-------+-------+-------------------+--------------------+------+-------+--------+------------------+---------------------------+\n",
      "| 13351|   1948|     M| 2016|     4|   116|            IRL|             IE|   116|            IRL|             IE|    BGM|           USA|java.util.Gregori...|      1|     ME|0.13800992941739443|java.util.Gregori...|    68|      1|      B1|             60886|          5.468230559553189|\n",
      "| 26320|   1970|     M| 2016|     4|   131|            CHE|             CH|   131|            CHE|             CH|    BGM|           USA|java.util.Gregori...|      1|     OH|0.07224299490350554|java.util.Gregori...|    46|      1|      B1|             82579|         1.9049338945858585|\n",
      "|154968|   1974|     M| 2016|     4|   582|            MEX|             MX|   582|            MEX|             MX|    BGM|           USA|java.util.Gregori...|      1|     ME|0.13800992941739443|java.util.Gregori...|    42|      1|      B1|              9852|           2.50794683412483|\n",
      "|155457|   1974|     M| 2016|     4|   582|            MEX|             MX|   582|            MEX|             MX|    BGM|           USA|java.util.Gregori...|      1|     ME|0.13800992941739443|java.util.Gregori...|    42|      1|      B1|              9852|           2.50794683412483|\n",
      "|155458|   1975|     M| 2016|     4|   582|            MEX|             MX|   582|            MEX|             MX|    BGM|           USA|java.util.Gregori...|      1|     ME|0.13800992941739443|java.util.Gregori...|    41|      1|      B1|              9852|           2.50794683412483|\n",
      "+------+-------+------+-----+------+------+---------------+---------------+------+---------------+---------------+-------+--------------+--------------------+-------+-------+-------------------+--------------------+------+-------+--------+------------------+---------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df_immigration_facts.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "\n",
    "As we firstly store our results from Pandas in csv files, and then we import them in Spark, we want to check that these files have been stored in their totality.\n",
    "\n",
    "So we design a preliminary check to check that everything has gone well, by comparing the rows in our temporary views with the number of rows of the corresponding DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_check_query_01 = \"SELECT COUNT(*) FROM airports_treated\"\n",
    "qual_check_query_02 = \"SELECT COUNT(*) FROM demographics_treated\"\n",
    "qual_check_query_03 = \"SELECT COUNT(*) FROM temperatures_treated\"\n",
    "qual_check_query_04 = \"SELECT COUNT(*) FROM countries_treated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_qual_checks ={qual_check_query_01:df_airports.shape[0], \n",
    "                   qual_check_query_02:df_demographics.shape[0], \n",
    "                   qual_check_query_03:df_temperatures_total_gr.shape[0], \n",
    "                   qual_check_query_04:df_countries_final.shape[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(*) FROM airports_treated : PASSED\n",
      "SELECT COUNT(*) FROM demographics_treated : PASSED\n",
      "SELECT COUNT(*) FROM temperatures_treated : PASSED\n",
      "SELECT COUNT(*) FROM countries_treated : PASSED\n"
     ]
    }
   ],
   "source": [
    "for query, value in open_qual_checks.items():\n",
    "    result = spark.sql(query).first()[0]\n",
    "    if result == value:\n",
    "        print(query, \": PASSED\")\n",
    "    else:\n",
    "        print(query, \": FAILED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to check if our operations have gone as expected by checking the number of rows in our immigration_facts_table and comparing that number with the number of rows that immigration_sample_treated_code has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check passed succesfully\n",
      "immigration_treated has 2699631 rows\n",
      "immigration_facts_table has 2699631 rows\n"
     ]
    }
   ],
   "source": [
    "qual_check_query_05 = \"SELECT COUNT(*) FROM immigration_sample_treated_code\"\n",
    "qual_check_query_06 = \"SELECT COUNT(*) FROM immigration_facts_table\"\n",
    "\n",
    "result_final_1 = spark.sql(qual_check_query_05).first()[0]\n",
    "result_final_2 = spark.sql(qual_check_query_06).first()[0]\n",
    "\n",
    "if result_final_1 == result_final_2:\n",
    "    print(\"Check passed succesfully\")\n",
    "    print(\"immigration_treated has {} rows\".format(result_final_1))\n",
    "    print(\"immigration_facts_table has {} rows\".format(result_final_2))\n",
    "else:\n",
    "    print(\"\"\"Check failed.\\n\n",
    "            Table immigration_facts_table has {} records while table immigration_treated has {} records.\\n\n",
    "            Check whether this is correct.\"\"\"\n",
    "         .format(result_final_1, result_final_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Storing the results\n",
    "\n",
    "And now, we store the resulting tables in a parque file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_demographics_treated_grouped = './out/immigration_table_results'\n",
    "spark_df_immigration_facts.write.parquet(output_df_demographics_treated_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['State',\n",
       " 'State Code',\n",
       " 'Median_Age',\n",
       " 'Male_Population',\n",
       " 'Female_Population',\n",
       " 'Total_Population',\n",
       " 'Foreignborn',\n",
       " 'Average_Household_Size',\n",
       " 'Percent_Foreignborn']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df_demographics_treated_code.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Data dictionary \n",
    "\n",
    "Here we leave a Data dictionary explaining the values stored in our file:\n",
    "\n",
    "**immigration_facts_table:**\n",
    "\n",
    "    cicid--> CIC's foreign traveler id\n",
    "\n",
    "    biryear--> date of birth of such foreigner\n",
    "\n",
    "    gender--> gender of the foreigner (values as \"0\" and \"X\" exist for unknown data)\n",
    "\n",
    "    i94yr--> year of the travel\n",
    "\n",
    "    i94mon--> month of the travel\n",
    "\n",
    "    i94cit--> USA-CIC's traveler's country of citizenship\n",
    "\n",
    "    cit_CountryCode--> Country Code of traveler's country of citizenship\n",
    "\n",
    "    cit_iso_country--> ISO Country Code of traveler's country of citizenship\n",
    "\n",
    "    i94res--> USA-CIC's traveler's country of residence\n",
    "\n",
    "    res_CountryCode--> Country Code of traveler's country of residence\n",
    "\n",
    "    res_iso_country--> ISO Country Code of traveler's country of residence\n",
    "\n",
    "    i94port--> i94 code destination airport\n",
    "\n",
    "    CountryAirport--> Airport's country\n",
    "\n",
    "    arrdate--> Date of arraival\n",
    "\n",
    "    i94mode--> Way the traveler has entered the USA: values include 'Air', 'Sea', 'Land' and 'Not reported'\n",
    "\n",
    "    i94addr--> State code of traveler's residence address\n",
    "\n",
    "    percent_foreignborn--> State's percentage of people foreign born, as calculated aggregatin data from the demographics file (differences to real data may exist)\n",
    "\n",
    "    depdate--> Date of departure for the foreigner\n",
    "\n",
    "    i94bir--> Age of the respondent in years\n",
    "\n",
    "    i94visa--> Type of visa the respondent holds\n",
    "\n",
    "    visatype--> Type of visa hold by traveler\n",
    "\n",
    "    res_avg_GDP_capita--> Average GDP per capita (of last 10 years) of traveler's country of residence\n",
    "\n",
    "    res_GDPcapita_annual_change--> Average annual percent increase of decrease of the GDP per capita of traveler's country of residence (calculated over the last 10 years)\n",
    "    \n",
    " **airports_treated_code:**\n",
    " \n",
    "    ident--> Airport's identity code\n",
    "    \n",
    "    type--> Kind of airport (small_airport, medium_airport, large_aiport, etc...)\n",
    "    \n",
    "    name--> Airport's name\n",
    "    \n",
    "    iso_country--> ISO code for airport's country\n",
    "    \n",
    "    iso_region--> ISO code for airport's region\n",
    "    \n",
    "    municipality--> Airport's city\n",
    "    \n",
    "    gps_code--> Airport's GPS code\n",
    "    \n",
    "    iata_code--> Airport's code in IATA tables\n",
    "    \n",
    "    local_code--> Local designation\n",
    "    \n",
    "    longitude--> Airport's longitude\n",
    "    \n",
    "    latitude--> Airport's latitude\n",
    "    \n",
    "    CountryCode--> Airport's country code\n",
    "    \n",
    "    i94cntyl--> I94 airport's code\n",
    "    \n",
    "    \n",
    " **demographics_treated_grouped:**  \n",
    "    \n",
    "    State--> USA's State Name\n",
    "\n",
    "    State Code--> USA's 2-letter code\n",
    "\n",
    "    Median_Age--> State's median age, as per the aggregation of the value from the demographics dataset\n",
    "\n",
    "    Male_Population--> Number of males in state, as per the aggregation of the value from the demographics dataset\n",
    "\n",
    "    Female_Population--> Number of females in state, as per the aggregation of the value from the demographics dataset\n",
    "\n",
    "    Total_Population--> State's total population, as per the aggregation of the value from the demographics dataset\n",
    "\n",
    "    Foreignborn--> Number of people born abroad in the state, as per the aggregation of the value from the demographics dataset\n",
    "\n",
    "    Average_Household_Size--> State's average household size, as per the aggregation of the value from the demographics dataset\n",
    "\n",
    "    Percent_Foreignborn--> Percentage of people born abroad, as per the aggregation of the value from the demographics dataset\n",
    "    \n",
    "    \n",
    "**temperatures_treated:**   \n",
    "    \n",
    "    month--> month of record\n",
    "\n",
    "    year--> year of record\n",
    "\n",
    "    City--> City of record\n",
    "\n",
    "    Country--> Country's city of record\n",
    "\n",
    "    AverageTemperature--> Month's average temperature (last 10 years: 2010-2019)\n",
    "\n",
    "    AverageTemperatureUncertainty--> Month's average temperature uncertainty (last 10 years: 2010-2019)\n",
    "\n",
    "    AvgTotal--> City's average temperature for the last 10 years (2010-2019)\n",
    "    \n",
    "**countries_treated:**    \n",
    "    \n",
    "    Country Name--> Name of the country\n",
    "\n",
    "    Country Code--> Country 3-digit code\n",
    "\n",
    "    avg_GDP per capita_capita--> Last 10 year's average GDP per capita data\n",
    "\n",
    "    max_year--> year of last available medition\n",
    "\n",
    "    GDP per capita_capita_max_year--> GDP per capita of last year available\n",
    "\n",
    "    min_year--> year of first medition since 2010 available\n",
    "\n",
    "    GDP per capita_capita_min_year--> GDP per capita of that year\n",
    "\n",
    "    %_change--> annual average GDP per capita increase, in percentage points\n",
    "    \n",
    "\n",
    "**country_codes:**\n",
    "\n",
    "    Country--> Country's name\n",
    "\n",
    "    Country_norm--> Country's name \"normalized\" (some minor misspellings corrected, plus other corrections)\n",
    "\n",
    "    iso_country--> Country's ISO code\n",
    "\n",
    "    CountryCode--> Country's 3-digit code\n",
    "\n",
    "    CodeNum--> Country's international code number\n",
    "\n",
    "    i94cntyl--> i94 Country's number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Complete Project Write Up\n",
    "\n",
    "Along this project, we have used a series of technologies that have allowed us the handling of our data. Because of its flexibility, the possibility of coding in Jupyter notebooks and the huge ammount of modules and tools availables, Python has been the language of choice.\n",
    "  \n",
    "Now, For the smaller datasets, we have chosen Pandas for the data cleaning. Even for the world temperatures dataset the process is manageable in Pandas, loading the file in chunks. \n",
    "\n",
    "Nevertheless, for the big immigration files we have had to resort to Spark.\n",
    "\n",
    "Then, for the creation of the data model, we could manage the situation with SQL (employing MySQL workbench, queries in the 'Auxiliary' folder), when using a sample of the immigration dataset, but Spark was needed again when treating the big files, and so, all out data model pipelines were executed in Spark.\n",
    "\n",
    "For this reason, we decided to store our smaller files (all other data but the immigration data), once treated, in csv files, and create Spark DataFrames for these smaller datasets to have them available for our data queries in pypark.\n",
    "\n",
    "We, then, defined our data pipeline in Spark, creating the desired tables, running the required checks and storing the main table in a parquet file.\n",
    "\n",
    "Now, we would propose to run this model once a month to update the data, since it seems that the immigration files have a monthly periodicity, and are the core of the information needed to run our Machine Learning algorithms.\n",
    "    \n",
    "#### Scenarios\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    "    1. the data was increased by 100x.\n",
    "        - We should go for Amazon Redshift: It is an analytical database that is optimized for aggregation and read-heavy workloads\n",
    "    2. The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "        - If the data volume was not increased, it would be possible to keep using the same tools.\n",
    "        - Airflow can be used here, to ease the workload and automate the runs. It allows us also to use DAG retries or send emails in the event of failure.\n",
    "        - Have daily quality checks; if fail, send emails to operators and freeze dashboards\n",
    "    3. The database needed to be accessed by 100+ people.\n",
    "        - Again, for huge availability, AWS, with S3 and Redshift would be the tool of choice since their auto-scaling capabilities and good read performance would fit our needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
